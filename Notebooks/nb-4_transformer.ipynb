{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ-anUIDMlWt"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/retowuest/uio-dl-2024/blob/main/Notebooks/nb-4.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWXQzp4cMlWv"
      },
      "source": [
        "# Deep Learning for Social Scientists\n",
        "\n",
        "### University of Oslo, November 27-28, 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqcETaiBMlWv"
      },
      "source": [
        "### **Demo 5:**<br>Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtViPEaPMlWw"
      },
      "source": [
        "### Table of Contents\n",
        "* [Introduction](#section_1)\n",
        "* [Loading the Data](#section_2)\n",
        "* [Loading and Fine-Tuning a Pre-Trained BERT Model](#section_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGxfADQnMlWw"
      },
      "source": [
        "### Introduction <a class=\"anchor\" id=\"section_1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6F55uo8MlWx"
      },
      "source": [
        "In this demo, our goal is to fine-tune a BERT model for sentiment classification in PyTorch. We will use the open-source `transformers` [Python library](https://huggingface.co/docs/transformers/index) provided by [Hugging Face](https://huggingface.co/), which includes a number of pre-trained models that are ready for fine-tuning.\n",
        "\n",
        "We will use as our use case the IMDb movie review data set and fine-tune the distilled BERT model (`DistilBERT`) to perform sentiment classification. `DistilBERT` is a lightweight transformer model created by distilling a pre-trained BERT base model. The original uncased BERT base model contains over 110 million parameters. According to Hugging Face (see quote below), `DistilBERT` has 40% fewer parameters and runs 60% faster while preserving 95% of BERT's performance on the GLUE language understanding benchmark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLnBDCbKMlWy"
      },
      "source": [
        "---\n",
        "\n",
        "Quote from https://huggingface.co/docs/transformers/model_doc/distilbert:\n",
        "\n",
        "> DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. It has 40% less parameters than *google-bert/bert-base-uncased*, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPgPdG7lMlWy"
      },
      "source": [
        "### Loading the Data <a class=\"anchor\" id=\"section_1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50bULi9wMlWz"
      },
      "source": [
        "We will begin by loading the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfr4npayMlWz"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import gzip\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "\n",
        "import transformers\n",
        "from transformers import DistilBertTokenizerFast\n",
        "from transformers import DistilBertForSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqJavEHtMlW0"
      },
      "source": [
        "Next, we specify some general settings (number of epochs we use for training the model, device specification, and the random seed)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yNJimEkMlW0"
      },
      "outputs": [],
      "source": [
        "random_seed = 123\n",
        "torch.manual_seed(random_seed)\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "num_epochs = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BLAQPcfMlW0"
      },
      "source": [
        "Next, we will fetch the compressed IMDb movie review dataset (http://ai.stanford.edu/~amaas/data/sentiment/) for positive-negative sentiment classification, unzip it, and write it into a CSV-formatted file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP6LFuKuMlW0"
      },
      "outputs": [],
      "source": [
        "url = \"https://github.com/rasbt/machine-learning-book/raw/main/ch08/movie_data.csv.gz\"\n",
        "filename = url.split(\"/\")[-1]\n",
        "\n",
        "with open(filename, \"wb\") as f:\n",
        "    r = requests.get(url)\n",
        "    f.write(r.content)\n",
        "\n",
        "with gzip.open(\"movie_data.csv.gz\", \"rb\") as f_in:\n",
        "    with open(\"movie_data.csv\", \"wb\") as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)  # copy content from source file to destination file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jefaRbboMlW0"
      },
      "source": [
        "Check if the data set looks okay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qugpg4iLMlW0",
        "outputId": "dc1781ed-b9ba-4742-ad9e-c61a0e38ed41"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hi for all the people who have seen this wonde...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I recently bought the DVD, forgetting just how...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
              "1  OK... so... I really like Kris Kristofferson a...          0\n",
              "2  ***SPOILER*** Do not read this, if you think a...          0\n",
              "3  hi for all the people who have seen this wonde...          1\n",
              "4  I recently bought the DVD, forgetting just how...          0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load data into a Pandas DataFrame and print first few rows\n",
        "df = pd.read_csv(\"movie_data.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUamt_oLMlW1",
        "outputId": "d42bdfaf-2022-458c-98c4-d2d3b39d0e81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print dimensions of dataframe\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7jt32yaMlW1"
      },
      "source": [
        "The next step is to split data set into training, validation, and test sets. We use 70% (or 35,000 examples) of the data for training, 10% (or 5,000 examples) for validation, and the remaining 20% (or 10,000 examples) for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXWedt53MlW1"
      },
      "outputs": [],
      "source": [
        "# Split data into training, validation, and test sets\n",
        "train_texts = df.iloc[:35000][\"review\"].values\n",
        "train_labels = df.iloc[:35000][\"sentiment\"].values\n",
        "\n",
        "valid_texts = df.iloc[35000:40000][\"review\"].values\n",
        "valid_labels = df.iloc[35000:40000][\"sentiment\"].values\n",
        "\n",
        "test_texts = df.iloc[40000:][\"review\"].values\n",
        "test_labels = df.iloc[40000:][\"sentiment\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRktYQx_MlW1"
      },
      "source": [
        "Next, we will tokenize the texts into individual word tokens using the tokenizer implementation inherited from the pre-trained model class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f30dDLJvMlW1",
        "outputId": "ce67b5b7-a452-4e97-c453-85741043e5e6",
        "colab": {
          "referenced_widgets": [
            "03813641d7d24c75b092a865b638fc45"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03813641d7d24c75b092a865b638fc45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Inherited tokenizers maintain consistency between the pre-trained model and the data\n",
        "# (hence, using an inherited tokenizer is recommended when fine-tuning\n",
        "# a pre-trained model)\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\n",
        "    \"distilbert-base-uncased\", model_max_length=512\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZsOUjSNMlW2"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)  # truncation=True: inputs longer than the model's maximum input length are truncated to fit within the model's limit (it has maximum input length of 512 tokens, see previous cell)\n",
        "valid_encodings = tokenizer(list(valid_texts), truncation=True, padding=True)  # padding=True: shorter sequences are padded to the same length as the longest sequence in the batch (model requires all sequences in a batch to be of uniform length)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xX3WLcyMlW2"
      },
      "source": [
        "Finally, we create a class called `IMDbDataset` and create the data loaders (the encodings store a lot of information about the tokenized texts; with the dictionary in the `__getitem__` method defined below, we extract only the relevant information)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsXBsR8qMlW2"
      },
      "outputs": [],
      "source": [
        "# Create class IMDbDataset\n",
        "class IMDbDataset(torch.utils.data.Dataset):  # creating subclass of torch.utils.data.Dataset (i.e., we inherit from this class and can override its functionality)\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    # We override two methods from torch.utils.data.Dataset class\n",
        "    def __getitem__(self, idx):  # extract data at specified index from encodings and labels and convert them into tensors\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):  # specify length of data set which is determined by number of labels\n",
        "        return len(self.labels)\n",
        "\n",
        "# Apply class to create training, validation, and test sets\n",
        "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
        "valid_dataset = IMDbDataset(valid_encodings, valid_labels)\n",
        "test_dataset = IMDbDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO5q9VPwMlW2"
      },
      "outputs": [],
      "source": [
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUF0tInUMlW3"
      },
      "source": [
        "### Loading and Fine-Tuning a Pre-Trained BERT Model <a class=\"anchor\" id=\"section_3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2krHpgv7MlW3"
      },
      "source": [
        "We first load the pre-trained BERT model (\"uncased\" means that the model does not distinguish between upper- and lower-case letters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZuglwTnMlW3",
        "outputId": "7bae4c81-8c68-4c0c-fb0f-32b74693ff2f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained model that we want to fine-tune\n",
        "# (DistilBertForSequenceClassification specifies the downstream task for which\n",
        "# we want to fine-tune the model, which is sequence classification)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "model.to(device)\n",
        "model.train();\n",
        "\n",
        "# Message below means:\n",
        "# - The DistilBertForSequenceClassification class adds additional layers on top of the\n",
        "#   pretrained model to perform sequence classification\n",
        "# - These layers are not part of the pretrained checkpoint and are randomly initialized\n",
        "#   when the model is created (as such they need to be trained)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWO39VuwMlW3"
      },
      "source": [
        "To train (fine-tune) the model, we will use the `Trainer` API provided by `Hugging Face`, which is optimized for transformer models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Az728pCEMlW3"
      },
      "outputs": [],
      "source": [
        "# Import Trainer and TrainingArguments from transformers\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Specify optimization algorithm\n",
        "optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Specify training arguments\n",
        "# (directories for output and logs, number of epochs, batch sizes)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "# Pass TrainingArguments settings to the Trainer class to instantiate a new trainer object\n",
        "trainer = Trainer(\n",
        "    model=model,  # the model to be fine-tuned\n",
        "    args=training_args,  # training arguments specified above\n",
        "    train_dataset=train_dataset,  # training set\n",
        "    optimizers=(optim, None)  # optim and learning rate schedule\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECfBBljFMlW3"
      },
      "source": [
        "We can now train the model by calling the `trainer.train` method (we will use this method shortly).\n",
        "\n",
        "The `Trainer` API only shows the training loss and does not provide model evaluation. Therefore, to evaluate the model, we define an evaluation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QykF_MGMlW3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Import load_metrics and numpy\n",
        "from datasets import load_metric\n",
        "import numpy as np\n",
        "\n",
        "# Define metric\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "# Define evaluation function\n",
        "# (function operates on the model's test predictions as logits, which is the default output of the model, and the labels)\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred  # logits are a numpy array, not pytorch tensor\n",
        "    predictions = np.argmax(logits, axis=-1)  # the compute_metrics function operates on the model's test predictions as logits (domain is real line)\n",
        "    return metric.compute(\n",
        "        predictions=predictions, references=labels\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah9evuICMlW4"
      },
      "outputs": [],
      "source": [
        "# Run trainer again, this time including test set and compute_metrics\n",
        "optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    compute_metrics=compute_metrics,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    optimizers=(optim, None)  # optimizer and learning rate scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdkWVgScMlW4",
        "outputId": "406fcea5-020a-4fb3-eb11-d74a27220f6a",
        "colab": {
          "referenced_widgets": [
            "3a50f7f50d5e4431ad914bc7d0c96371"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a50f7f50d5e4431ad914bc7d0c96371",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6564 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6807, 'grad_norm': 1.4945377111434937, 'learning_rate': 4.9923826934795856e-05, 'epoch': 0.0}\n",
            "{'loss': 0.6027, 'grad_norm': 3.1703603267669678, 'learning_rate': 4.984765386959172e-05, 'epoch': 0.01}\n",
            "{'loss': 0.5401, 'grad_norm': 5.817531108856201, 'learning_rate': 4.977148080438757e-05, 'epoch': 0.01}\n",
            "{'loss': 0.3642, 'grad_norm': 5.309085845947266, 'learning_rate': 4.9695307739183424e-05, 'epoch': 0.02}\n",
            "{'loss': 0.3551, 'grad_norm': 13.325989723205566, 'learning_rate': 4.9619134673979285e-05, 'epoch': 0.02}\n",
            "{'loss': 0.4475, 'grad_norm': 8.179169654846191, 'learning_rate': 4.954296160877514e-05, 'epoch': 0.03}\n",
            "{'loss': 0.3234, 'grad_norm': 1.8053861856460571, 'learning_rate': 4.9466788543571e-05, 'epoch': 0.03}\n",
            "{'loss': 0.3941, 'grad_norm': 7.565412998199463, 'learning_rate': 4.939061547836685e-05, 'epoch': 0.04}\n",
            "{'loss': 0.3482, 'grad_norm': 5.218079090118408, 'learning_rate': 4.931444241316271e-05, 'epoch': 0.04}\n",
            "{'loss': 0.3749, 'grad_norm': 12.034934043884277, 'learning_rate': 4.923826934795857e-05, 'epoch': 0.05}\n",
            "{'loss': 0.3678, 'grad_norm': 7.7153706550598145, 'learning_rate': 4.916209628275442e-05, 'epoch': 0.05}\n",
            "{'loss': 0.3616, 'grad_norm': 5.565965175628662, 'learning_rate': 4.9085923217550275e-05, 'epoch': 0.05}\n",
            "{'loss': 0.2631, 'grad_norm': 4.5666890144348145, 'learning_rate': 4.9009750152346136e-05, 'epoch': 0.06}\n",
            "{'loss': 0.2664, 'grad_norm': 8.008340835571289, 'learning_rate': 4.893357708714199e-05, 'epoch': 0.06}\n",
            "{'loss': 0.2246, 'grad_norm': 7.497801303863525, 'learning_rate': 4.885740402193785e-05, 'epoch': 0.07}\n",
            "{'loss': 0.3016, 'grad_norm': 2.8951821327209473, 'learning_rate': 4.8781230956733704e-05, 'epoch': 0.07}\n",
            "{'loss': 0.2559, 'grad_norm': 4.067234039306641, 'learning_rate': 4.870505789152956e-05, 'epoch': 0.08}\n",
            "{'loss': 0.2839, 'grad_norm': 5.12466287612915, 'learning_rate': 4.862888482632542e-05, 'epoch': 0.08}\n",
            "{'loss': 0.2574, 'grad_norm': 1.988039493560791, 'learning_rate': 4.855271176112127e-05, 'epoch': 0.09}\n",
            "{'loss': 0.2766, 'grad_norm': 4.650425434112549, 'learning_rate': 4.8476538695917126e-05, 'epoch': 0.09}\n",
            "{'loss': 0.2758, 'grad_norm': 9.948792457580566, 'learning_rate': 4.8400365630712987e-05, 'epoch': 0.1}\n",
            "{'loss': 0.3538, 'grad_norm': 31.66469383239746, 'learning_rate': 4.8324192565508834e-05, 'epoch': 0.1}\n",
            "{'loss': 0.3979, 'grad_norm': 19.497283935546875, 'learning_rate': 4.8248019500304694e-05, 'epoch': 0.11}\n",
            "{'loss': 0.2001, 'grad_norm': 7.844278812408447, 'learning_rate': 4.817184643510055e-05, 'epoch': 0.11}\n",
            "{'loss': 0.204, 'grad_norm': 10.09148120880127, 'learning_rate': 4.80956733698964e-05, 'epoch': 0.11}\n",
            "{'loss': 0.2294, 'grad_norm': 11.088094711303711, 'learning_rate': 4.801950030469226e-05, 'epoch': 0.12}\n",
            "{'loss': 0.4714, 'grad_norm': 8.738823890686035, 'learning_rate': 4.7943327239488116e-05, 'epoch': 0.12}\n",
            "{'loss': 0.3175, 'grad_norm': 5.650296688079834, 'learning_rate': 4.786715417428398e-05, 'epoch': 0.13}\n",
            "{'loss': 0.2387, 'grad_norm': 2.7552266120910645, 'learning_rate': 4.779098110907983e-05, 'epoch': 0.13}\n",
            "{'loss': 0.4272, 'grad_norm': 1.756480097770691, 'learning_rate': 4.7714808043875684e-05, 'epoch': 0.14}\n",
            "{'loss': 0.3995, 'grad_norm': 6.062961578369141, 'learning_rate': 4.7638634978671545e-05, 'epoch': 0.14}\n",
            "{'loss': 0.3067, 'grad_norm': 4.3724212646484375, 'learning_rate': 4.75624619134674e-05, 'epoch': 0.15}\n",
            "{'loss': 0.3225, 'grad_norm': 7.403264045715332, 'learning_rate': 4.748628884826325e-05, 'epoch': 0.15}\n",
            "{'loss': 0.2683, 'grad_norm': 8.666242599487305, 'learning_rate': 4.741011578305911e-05, 'epoch': 0.16}\n",
            "{'loss': 0.2463, 'grad_norm': 21.8638858795166, 'learning_rate': 4.733394271785497e-05, 'epoch': 0.16}\n",
            "{'loss': 0.3878, 'grad_norm': 8.338532447814941, 'learning_rate': 4.725776965265082e-05, 'epoch': 0.16}\n",
            "{'loss': 0.2936, 'grad_norm': 6.082164764404297, 'learning_rate': 4.718159658744668e-05, 'epoch': 0.17}\n",
            "{'loss': 0.2688, 'grad_norm': 5.081328392028809, 'learning_rate': 4.7105423522242535e-05, 'epoch': 0.17}\n",
            "{'loss': 0.2418, 'grad_norm': 6.783133506774902, 'learning_rate': 4.7029250457038396e-05, 'epoch': 0.18}\n",
            "{'loss': 0.3006, 'grad_norm': 8.129982948303223, 'learning_rate': 4.695307739183425e-05, 'epoch': 0.18}\n",
            "{'loss': 0.2622, 'grad_norm': 12.714837074279785, 'learning_rate': 4.6876904326630103e-05, 'epoch': 0.19}\n",
            "{'loss': 0.3012, 'grad_norm': 9.084790229797363, 'learning_rate': 4.6800731261425964e-05, 'epoch': 0.19}\n",
            "{'loss': 0.24, 'grad_norm': 4.186563491821289, 'learning_rate': 4.672455819622182e-05, 'epoch': 0.2}\n",
            "{'loss': 0.3077, 'grad_norm': 4.519967079162598, 'learning_rate': 4.664838513101767e-05, 'epoch': 0.2}\n",
            "{'loss': 0.2603, 'grad_norm': 6.963536262512207, 'learning_rate': 4.657221206581353e-05, 'epoch': 0.21}\n",
            "{'loss': 0.2578, 'grad_norm': 6.857113361358643, 'learning_rate': 4.6496039000609386e-05, 'epoch': 0.21}\n",
            "{'loss': 0.2241, 'grad_norm': 3.946570634841919, 'learning_rate': 4.641986593540525e-05, 'epoch': 0.21}\n",
            "{'loss': 0.3129, 'grad_norm': 4.679642677307129, 'learning_rate': 4.63436928702011e-05, 'epoch': 0.22}\n",
            "{'loss': 0.2947, 'grad_norm': 6.426681041717529, 'learning_rate': 4.6267519804996954e-05, 'epoch': 0.22}\n",
            "{'loss': 0.2137, 'grad_norm': 3.5472347736358643, 'learning_rate': 4.6191346739792815e-05, 'epoch': 0.23}\n",
            "{'loss': 0.2629, 'grad_norm': 8.412495613098145, 'learning_rate': 4.611517367458867e-05, 'epoch': 0.23}\n",
            "{'loss': 0.4182, 'grad_norm': 20.733997344970703, 'learning_rate': 4.603900060938452e-05, 'epoch': 0.24}\n",
            "{'loss': 0.1943, 'grad_norm': 13.666149139404297, 'learning_rate': 4.596282754418038e-05, 'epoch': 0.24}\n",
            "{'loss': 0.2757, 'grad_norm': 8.092461585998535, 'learning_rate': 4.588665447897624e-05, 'epoch': 0.25}\n",
            "{'loss': 0.2955, 'grad_norm': 2.8777685165405273, 'learning_rate': 4.581048141377209e-05, 'epoch': 0.25}\n",
            "{'loss': 0.2943, 'grad_norm': 3.3354454040527344, 'learning_rate': 4.573430834856795e-05, 'epoch': 0.26}\n",
            "{'loss': 0.2407, 'grad_norm': 4.800052642822266, 'learning_rate': 4.5658135283363805e-05, 'epoch': 0.26}\n",
            "{'loss': 0.2783, 'grad_norm': 3.862762689590454, 'learning_rate': 4.5581962218159666e-05, 'epoch': 0.27}\n",
            "{'loss': 0.2702, 'grad_norm': 1.0895371437072754, 'learning_rate': 4.550578915295552e-05, 'epoch': 0.27}\n",
            "{'loss': 0.2641, 'grad_norm': 4.73676061630249, 'learning_rate': 4.542961608775137e-05, 'epoch': 0.27}\n",
            "{'loss': 0.2961, 'grad_norm': 3.8650717735290527, 'learning_rate': 4.5353443022547234e-05, 'epoch': 0.28}\n",
            "{'loss': 0.2896, 'grad_norm': 5.934537410736084, 'learning_rate': 4.527726995734309e-05, 'epoch': 0.28}\n",
            "{'loss': 0.2577, 'grad_norm': 4.705204486846924, 'learning_rate': 4.520109689213894e-05, 'epoch': 0.29}\n",
            "{'loss': 0.2403, 'grad_norm': 6.620944976806641, 'learning_rate': 4.51249238269348e-05, 'epoch': 0.29}\n",
            "{'loss': 0.3696, 'grad_norm': 8.133381843566895, 'learning_rate': 4.504875076173065e-05, 'epoch': 0.3}\n",
            "{'loss': 0.2857, 'grad_norm': 4.051787853240967, 'learning_rate': 4.497257769652651e-05, 'epoch': 0.3}\n",
            "{'loss': 0.2554, 'grad_norm': 5.063080787658691, 'learning_rate': 4.4896404631322363e-05, 'epoch': 0.31}\n",
            "{'loss': 0.3107, 'grad_norm': 7.838711738586426, 'learning_rate': 4.482023156611822e-05, 'epoch': 0.31}\n",
            "{'loss': 0.2636, 'grad_norm': 7.21853494644165, 'learning_rate': 4.474405850091408e-05, 'epoch': 0.32}\n",
            "{'loss': 0.267, 'grad_norm': 7.200977802276611, 'learning_rate': 4.466788543570993e-05, 'epoch': 0.32}\n",
            "{'loss': 0.2539, 'grad_norm': 5.455557346343994, 'learning_rate': 4.459171237050579e-05, 'epoch': 0.32}\n",
            "{'loss': 0.2029, 'grad_norm': 3.9908833503723145, 'learning_rate': 4.4515539305301646e-05, 'epoch': 0.33}\n",
            "{'loss': 0.2091, 'grad_norm': 1.241639494895935, 'learning_rate': 4.44393662400975e-05, 'epoch': 0.33}\n",
            "{'loss': 0.1965, 'grad_norm': 12.797901153564453, 'learning_rate': 4.436319317489336e-05, 'epoch': 0.34}\n",
            "{'loss': 0.2433, 'grad_norm': 8.500174522399902, 'learning_rate': 4.4287020109689214e-05, 'epoch': 0.34}\n",
            "{'loss': 0.2741, 'grad_norm': 3.896268367767334, 'learning_rate': 4.421084704448507e-05, 'epoch': 0.35}\n",
            "{'loss': 0.2256, 'grad_norm': 0.9412482380867004, 'learning_rate': 4.413467397928093e-05, 'epoch': 0.35}\n",
            "{'loss': 0.3382, 'grad_norm': 3.5745768547058105, 'learning_rate': 4.405850091407678e-05, 'epoch': 0.36}\n",
            "{'loss': 0.2388, 'grad_norm': 5.639207363128662, 'learning_rate': 4.398232784887264e-05, 'epoch': 0.36}\n",
            "{'loss': 0.1779, 'grad_norm': 7.714121341705322, 'learning_rate': 4.39061547836685e-05, 'epoch': 0.37}\n",
            "{'loss': 0.2348, 'grad_norm': 11.265935897827148, 'learning_rate': 4.382998171846435e-05, 'epoch': 0.37}\n",
            "{'loss': 0.2969, 'grad_norm': 2.992812156677246, 'learning_rate': 4.375380865326021e-05, 'epoch': 0.37}\n",
            "{'loss': 0.2533, 'grad_norm': 2.4190237522125244, 'learning_rate': 4.3677635588056065e-05, 'epoch': 0.38}\n",
            "{'loss': 0.2144, 'grad_norm': 4.000866413116455, 'learning_rate': 4.360146252285192e-05, 'epoch': 0.38}\n",
            "{'loss': 0.3084, 'grad_norm': 6.292106628417969, 'learning_rate': 4.352528945764778e-05, 'epoch': 0.39}\n",
            "{'loss': 0.2431, 'grad_norm': 8.567432403564453, 'learning_rate': 4.344911639244363e-05, 'epoch': 0.39}\n",
            "{'loss': 0.3291, 'grad_norm': 4.813658714294434, 'learning_rate': 4.337294332723949e-05, 'epoch': 0.4}\n",
            "{'loss': 0.2058, 'grad_norm': 4.592982292175293, 'learning_rate': 4.329677026203535e-05, 'epoch': 0.4}\n",
            "{'loss': 0.2378, 'grad_norm': 2.782196283340454, 'learning_rate': 4.32205971968312e-05, 'epoch': 0.41}\n",
            "{'loss': 0.3474, 'grad_norm': 6.431061267852783, 'learning_rate': 4.314442413162706e-05, 'epoch': 0.41}\n",
            "{'loss': 0.251, 'grad_norm': 4.638162612915039, 'learning_rate': 4.3068251066422916e-05, 'epoch': 0.42}\n",
            "{'loss': 0.2318, 'grad_norm': 3.4721150398254395, 'learning_rate': 4.299207800121877e-05, 'epoch': 0.42}\n",
            "{'loss': 0.2127, 'grad_norm': 3.225417375564575, 'learning_rate': 4.291590493601463e-05, 'epoch': 0.43}\n",
            "{'loss': 0.3813, 'grad_norm': 6.2975544929504395, 'learning_rate': 4.2839731870810484e-05, 'epoch': 0.43}\n",
            "{'loss': 0.2578, 'grad_norm': 4.122344493865967, 'learning_rate': 4.276355880560634e-05, 'epoch': 0.43}\n",
            "{'loss': 0.1799, 'grad_norm': 8.263860702514648, 'learning_rate': 4.26873857404022e-05, 'epoch': 0.44}\n",
            "{'loss': 0.2786, 'grad_norm': 3.948572874069214, 'learning_rate': 4.261121267519805e-05, 'epoch': 0.44}\n",
            "{'loss': 0.2145, 'grad_norm': 4.014152526855469, 'learning_rate': 4.253503960999391e-05, 'epoch': 0.45}\n",
            "{'loss': 0.2622, 'grad_norm': 5.267008304595947, 'learning_rate': 4.245886654478977e-05, 'epoch': 0.45}\n",
            "{'loss': 0.1874, 'grad_norm': 3.6893062591552734, 'learning_rate': 4.238269347958562e-05, 'epoch': 0.46}\n",
            "{'loss': 0.3677, 'grad_norm': 1.4187294244766235, 'learning_rate': 4.230652041438148e-05, 'epoch': 0.46}\n",
            "{'loss': 0.2104, 'grad_norm': 1.2439335584640503, 'learning_rate': 4.2230347349177335e-05, 'epoch': 0.47}\n",
            "{'loss': 0.2317, 'grad_norm': 0.36898931860923767, 'learning_rate': 4.215417428397319e-05, 'epoch': 0.47}\n",
            "{'loss': 0.2814, 'grad_norm': 7.882382869720459, 'learning_rate': 4.207800121876905e-05, 'epoch': 0.48}\n",
            "{'loss': 0.101, 'grad_norm': 3.6502492427825928, 'learning_rate': 4.20018281535649e-05, 'epoch': 0.48}\n",
            "{'loss': 0.2798, 'grad_norm': 3.2784669399261475, 'learning_rate': 4.192565508836076e-05, 'epoch': 0.48}\n",
            "{'loss': 0.2461, 'grad_norm': 4.155369281768799, 'learning_rate': 4.184948202315662e-05, 'epoch': 0.49}\n",
            "{'loss': 0.2224, 'grad_norm': 4.782096862792969, 'learning_rate': 4.1773308957952465e-05, 'epoch': 0.49}\n",
            "{'loss': 0.1612, 'grad_norm': 0.34514448046684265, 'learning_rate': 4.1697135892748325e-05, 'epoch': 0.5}\n",
            "{'loss': 0.346, 'grad_norm': 10.22194766998291, 'learning_rate': 4.162096282754418e-05, 'epoch': 0.5}\n",
            "{'loss': 0.2187, 'grad_norm': 0.6262770295143127, 'learning_rate': 4.154478976234004e-05, 'epoch': 0.51}\n",
            "{'loss': 0.1746, 'grad_norm': 2.057961940765381, 'learning_rate': 4.146861669713589e-05, 'epoch': 0.51}\n",
            "{'loss': 0.237, 'grad_norm': 6.39786434173584, 'learning_rate': 4.139244363193175e-05, 'epoch': 0.52}\n",
            "{'loss': 0.2373, 'grad_norm': 6.6898016929626465, 'learning_rate': 4.131627056672761e-05, 'epoch': 0.52}\n",
            "{'loss': 0.4031, 'grad_norm': 12.6597900390625, 'learning_rate': 4.124009750152346e-05, 'epoch': 0.53}\n",
            "{'loss': 0.3147, 'grad_norm': 4.47974967956543, 'learning_rate': 4.1163924436319315e-05, 'epoch': 0.53}\n",
            "{'loss': 0.1746, 'grad_norm': 5.344949722290039, 'learning_rate': 4.1087751371115176e-05, 'epoch': 0.53}\n",
            "{'loss': 0.1878, 'grad_norm': 1.166059970855713, 'learning_rate': 4.101157830591103e-05, 'epoch': 0.54}\n",
            "{'loss': 0.2522, 'grad_norm': 10.733543395996094, 'learning_rate': 4.0935405240706884e-05, 'epoch': 0.54}\n",
            "{'loss': 0.1634, 'grad_norm': 2.583071708679199, 'learning_rate': 4.0859232175502744e-05, 'epoch': 0.55}\n",
            "{'loss': 0.3224, 'grad_norm': 5.473155498504639, 'learning_rate': 4.07830591102986e-05, 'epoch': 0.55}\n",
            "{'loss': 0.2145, 'grad_norm': 1.0152913331985474, 'learning_rate': 4.070688604509446e-05, 'epoch': 0.56}\n",
            "{'loss': 0.191, 'grad_norm': 5.083729267120361, 'learning_rate': 4.063071297989031e-05, 'epoch': 0.56}\n",
            "{'loss': 0.2988, 'grad_norm': 10.65381908416748, 'learning_rate': 4.0554539914686166e-05, 'epoch': 0.57}\n",
            "{'loss': 0.2831, 'grad_norm': 4.153222560882568, 'learning_rate': 4.047836684948203e-05, 'epoch': 0.57}\n",
            "{'loss': 0.2138, 'grad_norm': 4.04777717590332, 'learning_rate': 4.040219378427788e-05, 'epoch': 0.58}\n",
            "{'loss': 0.1885, 'grad_norm': 3.0781826972961426, 'learning_rate': 4.0326020719073734e-05, 'epoch': 0.58}\n",
            "{'loss': 0.278, 'grad_norm': 8.989710807800293, 'learning_rate': 4.0249847653869595e-05, 'epoch': 0.59}\n",
            "{'loss': 0.1555, 'grad_norm': 4.482179164886475, 'learning_rate': 4.017367458866545e-05, 'epoch': 0.59}\n",
            "{'loss': 0.1696, 'grad_norm': 7.00849723815918, 'learning_rate': 4.009750152346131e-05, 'epoch': 0.59}\n",
            "{'loss': 0.2685, 'grad_norm': 1.038581132888794, 'learning_rate': 4.002132845825716e-05, 'epoch': 0.6}\n",
            "{'loss': 0.3211, 'grad_norm': 6.751400470733643, 'learning_rate': 3.994515539305302e-05, 'epoch': 0.6}\n",
            "{'loss': 0.2478, 'grad_norm': 6.356099605560303, 'learning_rate': 3.986898232784888e-05, 'epoch': 0.61}\n",
            "{'loss': 0.2491, 'grad_norm': 4.435783863067627, 'learning_rate': 3.979280926264473e-05, 'epoch': 0.61}\n",
            "{'loss': 0.2377, 'grad_norm': 1.796647071838379, 'learning_rate': 3.9716636197440585e-05, 'epoch': 0.62}\n",
            "{'loss': 0.2953, 'grad_norm': 5.573575973510742, 'learning_rate': 3.9640463132236446e-05, 'epoch': 0.62}\n",
            "{'loss': 0.2346, 'grad_norm': 6.038219451904297, 'learning_rate': 3.95642900670323e-05, 'epoch': 0.63}\n",
            "{'loss': 0.2014, 'grad_norm': 2.3087027072906494, 'learning_rate': 3.948811700182815e-05, 'epoch': 0.63}\n",
            "{'loss': 0.1557, 'grad_norm': 4.326440811157227, 'learning_rate': 3.9411943936624014e-05, 'epoch': 0.64}\n",
            "{'loss': 0.2561, 'grad_norm': 4.411354064941406, 'learning_rate': 3.933577087141987e-05, 'epoch': 0.64}\n",
            "{'loss': 0.2233, 'grad_norm': 6.570058822631836, 'learning_rate': 3.925959780621573e-05, 'epoch': 0.64}\n",
            "{'loss': 0.2636, 'grad_norm': 5.415320873260498, 'learning_rate': 3.918342474101158e-05, 'epoch': 0.65}\n",
            "{'loss': 0.2136, 'grad_norm': 4.104001045227051, 'learning_rate': 3.9107251675807436e-05, 'epoch': 0.65}\n",
            "{'loss': 0.2576, 'grad_norm': 7.771914958953857, 'learning_rate': 3.9031078610603297e-05, 'epoch': 0.66}\n",
            "{'loss': 0.131, 'grad_norm': 4.404304027557373, 'learning_rate': 3.895490554539915e-05, 'epoch': 0.66}\n",
            "{'loss': 0.1935, 'grad_norm': 10.298565864562988, 'learning_rate': 3.8878732480195004e-05, 'epoch': 0.67}\n",
            "{'loss': 0.286, 'grad_norm': 9.762625694274902, 'learning_rate': 3.8802559414990865e-05, 'epoch': 0.67}\n",
            "{'loss': 0.2286, 'grad_norm': 13.092761039733887, 'learning_rate': 3.872638634978672e-05, 'epoch': 0.68}\n",
            "{'loss': 0.2449, 'grad_norm': 7.125516891479492, 'learning_rate': 3.865021328458258e-05, 'epoch': 0.68}\n",
            "{'loss': 0.2023, 'grad_norm': 4.312318325042725, 'learning_rate': 3.857404021937843e-05, 'epoch': 0.69}\n",
            "{'loss': 0.1361, 'grad_norm': 0.6135457158088684, 'learning_rate': 3.849786715417429e-05, 'epoch': 0.69}\n",
            "{'loss': 0.2576, 'grad_norm': 1.392402172088623, 'learning_rate': 3.842169408897014e-05, 'epoch': 0.69}\n",
            "{'loss': 0.2317, 'grad_norm': 11.464993476867676, 'learning_rate': 3.8345521023765994e-05, 'epoch': 0.7}\n",
            "{'loss': 0.2829, 'grad_norm': 6.2031731605529785, 'learning_rate': 3.8269347958561855e-05, 'epoch': 0.7}\n",
            "{'loss': 0.1562, 'grad_norm': 2.473482847213745, 'learning_rate': 3.819317489335771e-05, 'epoch': 0.71}\n",
            "{'loss': 0.2491, 'grad_norm': 7.032367706298828, 'learning_rate': 3.811700182815356e-05, 'epoch': 0.71}\n",
            "{'loss': 0.3127, 'grad_norm': 5.41157341003418, 'learning_rate': 3.804082876294942e-05, 'epoch': 0.72}\n",
            "{'loss': 0.1927, 'grad_norm': 1.152604341506958, 'learning_rate': 3.796465569774528e-05, 'epoch': 0.72}\n",
            "{'loss': 0.2592, 'grad_norm': 4.786625385284424, 'learning_rate': 3.788848263254113e-05, 'epoch': 0.73}\n",
            "{'loss': 0.191, 'grad_norm': 6.568308353424072, 'learning_rate': 3.781230956733699e-05, 'epoch': 0.73}\n",
            "{'loss': 0.3325, 'grad_norm': 2.8960835933685303, 'learning_rate': 3.7736136502132845e-05, 'epoch': 0.74}\n",
            "{'loss': 0.2321, 'grad_norm': 5.556490898132324, 'learning_rate': 3.7659963436928706e-05, 'epoch': 0.74}\n",
            "{'loss': 0.2337, 'grad_norm': 6.971017360687256, 'learning_rate': 3.758379037172456e-05, 'epoch': 0.74}\n",
            "{'loss': 0.1453, 'grad_norm': 4.794501781463623, 'learning_rate': 3.750761730652041e-05, 'epoch': 0.75}\n",
            "{'loss': 0.2834, 'grad_norm': 14.378413200378418, 'learning_rate': 3.7431444241316274e-05, 'epoch': 0.75}\n",
            "{'loss': 0.2192, 'grad_norm': 2.369121551513672, 'learning_rate': 3.735527117611213e-05, 'epoch': 0.76}\n",
            "{'loss': 0.2192, 'grad_norm': 3.669290781021118, 'learning_rate': 3.727909811090798e-05, 'epoch': 0.76}\n",
            "{'loss': 0.277, 'grad_norm': 6.946009159088135, 'learning_rate': 3.720292504570384e-05, 'epoch': 0.77}\n",
            "{'loss': 0.2697, 'grad_norm': 6.732109546661377, 'learning_rate': 3.7126751980499696e-05, 'epoch': 0.77}\n",
            "{'loss': 0.1959, 'grad_norm': 4.539112567901611, 'learning_rate': 3.705057891529555e-05, 'epoch': 0.78}\n",
            "{'loss': 0.192, 'grad_norm': 7.504024028778076, 'learning_rate': 3.697440585009141e-05, 'epoch': 0.78}\n",
            "{'loss': 0.2463, 'grad_norm': 3.7212610244750977, 'learning_rate': 3.6898232784887264e-05, 'epoch': 0.79}\n",
            "{'loss': 0.2413, 'grad_norm': 2.7921910285949707, 'learning_rate': 3.6822059719683125e-05, 'epoch': 0.79}\n",
            "{'loss': 0.2305, 'grad_norm': 4.899963855743408, 'learning_rate': 3.674588665447898e-05, 'epoch': 0.8}\n",
            "{'loss': 0.2039, 'grad_norm': 5.247555255889893, 'learning_rate': 3.666971358927483e-05, 'epoch': 0.8}\n",
            "{'loss': 0.173, 'grad_norm': 2.7483339309692383, 'learning_rate': 3.659354052407069e-05, 'epoch': 0.8}\n",
            "{'loss': 0.2224, 'grad_norm': 9.14601993560791, 'learning_rate': 3.651736745886655e-05, 'epoch': 0.81}\n",
            "{'loss': 0.1507, 'grad_norm': 4.310326099395752, 'learning_rate': 3.64411943936624e-05, 'epoch': 0.81}\n",
            "{'loss': 0.2425, 'grad_norm': 7.763791084289551, 'learning_rate': 3.636502132845826e-05, 'epoch': 0.82}\n",
            "{'loss': 0.289, 'grad_norm': 1.8966726064682007, 'learning_rate': 3.6288848263254115e-05, 'epoch': 0.82}\n",
            "{'loss': 0.2491, 'grad_norm': 4.657375812530518, 'learning_rate': 3.6212675198049976e-05, 'epoch': 0.83}\n",
            "{'loss': 0.193, 'grad_norm': 2.582089900970459, 'learning_rate': 3.613650213284583e-05, 'epoch': 0.83}\n",
            "{'loss': 0.2253, 'grad_norm': 5.568801403045654, 'learning_rate': 3.606032906764168e-05, 'epoch': 0.84}\n",
            "{'loss': 0.2217, 'grad_norm': 7.325183391571045, 'learning_rate': 3.5984156002437544e-05, 'epoch': 0.84}\n",
            "{'loss': 0.2216, 'grad_norm': 9.329699516296387, 'learning_rate': 3.59079829372334e-05, 'epoch': 0.85}\n",
            "{'loss': 0.3133, 'grad_norm': 11.189947128295898, 'learning_rate': 3.583180987202925e-05, 'epoch': 0.85}\n",
            "{'loss': 0.2201, 'grad_norm': 3.707702875137329, 'learning_rate': 3.575563680682511e-05, 'epoch': 0.85}\n",
            "{'loss': 0.2537, 'grad_norm': 5.842897891998291, 'learning_rate': 3.5679463741620966e-05, 'epoch': 0.86}\n",
            "{'loss': 0.191, 'grad_norm': 0.8031710386276245, 'learning_rate': 3.560329067641682e-05, 'epoch': 0.86}\n",
            "{'loss': 0.229, 'grad_norm': 8.146186828613281, 'learning_rate': 3.552711761121268e-05, 'epoch': 0.87}\n",
            "{'loss': 0.2497, 'grad_norm': 3.3248603343963623, 'learning_rate': 3.5450944546008534e-05, 'epoch': 0.87}\n",
            "{'loss': 0.2428, 'grad_norm': 8.474838256835938, 'learning_rate': 3.5374771480804395e-05, 'epoch': 0.88}\n",
            "{'loss': 0.2603, 'grad_norm': 4.589587211608887, 'learning_rate': 3.529859841560025e-05, 'epoch': 0.88}\n",
            "{'loss': 0.2872, 'grad_norm': 4.808986663818359, 'learning_rate': 3.52224253503961e-05, 'epoch': 0.89}\n",
            "{'loss': 0.1476, 'grad_norm': 0.43167218565940857, 'learning_rate': 3.5146252285191956e-05, 'epoch': 0.89}\n",
            "{'loss': 0.2638, 'grad_norm': 2.64837908744812, 'learning_rate': 3.507007921998781e-05, 'epoch': 0.9}\n",
            "{'loss': 0.1943, 'grad_norm': 2.7828571796417236, 'learning_rate': 3.499390615478367e-05, 'epoch': 0.9}\n",
            "{'loss': 0.179, 'grad_norm': 2.170820951461792, 'learning_rate': 3.4917733089579524e-05, 'epoch': 0.9}\n",
            "{'loss': 0.1925, 'grad_norm': 1.3946675062179565, 'learning_rate': 3.484156002437538e-05, 'epoch': 0.91}\n",
            "{'loss': 0.1878, 'grad_norm': 7.6866888999938965, 'learning_rate': 3.476538695917124e-05, 'epoch': 0.91}\n",
            "{'loss': 0.1348, 'grad_norm': 4.894773960113525, 'learning_rate': 3.468921389396709e-05, 'epoch': 0.92}\n",
            "{'loss': 0.2561, 'grad_norm': 5.855296611785889, 'learning_rate': 3.4613040828762946e-05, 'epoch': 0.92}\n",
            "{'loss': 0.2438, 'grad_norm': 3.643425464630127, 'learning_rate': 3.453686776355881e-05, 'epoch': 0.93}\n",
            "{'loss': 0.2898, 'grad_norm': 5.300628185272217, 'learning_rate': 3.446069469835466e-05, 'epoch': 0.93}\n",
            "{'loss': 0.1654, 'grad_norm': 3.009474039077759, 'learning_rate': 3.438452163315052e-05, 'epoch': 0.94}\n",
            "{'loss': 0.2048, 'grad_norm': 7.533349990844727, 'learning_rate': 3.4308348567946375e-05, 'epoch': 0.94}\n",
            "{'loss': 0.1431, 'grad_norm': 5.853664398193359, 'learning_rate': 3.423217550274223e-05, 'epoch': 0.95}\n",
            "{'loss': 0.1962, 'grad_norm': 6.2665205001831055, 'learning_rate': 3.415600243753809e-05, 'epoch': 0.95}\n",
            "{'loss': 0.2417, 'grad_norm': 11.384995460510254, 'learning_rate': 3.407982937233394e-05, 'epoch': 0.96}\n",
            "{'loss': 0.1201, 'grad_norm': 3.8909080028533936, 'learning_rate': 3.40036563071298e-05, 'epoch': 0.96}\n",
            "{'loss': 0.2229, 'grad_norm': 7.5874786376953125, 'learning_rate': 3.392748324192566e-05, 'epoch': 0.96}\n",
            "{'loss': 0.3372, 'grad_norm': 8.81528091430664, 'learning_rate': 3.385131017672151e-05, 'epoch': 0.97}\n",
            "{'loss': 0.1757, 'grad_norm': 6.6634297370910645, 'learning_rate': 3.377513711151737e-05, 'epoch': 0.97}\n",
            "{'loss': 0.2062, 'grad_norm': 1.5697914361953735, 'learning_rate': 3.3698964046313226e-05, 'epoch': 0.98}\n",
            "{'loss': 0.1064, 'grad_norm': 0.6417147517204285, 'learning_rate': 3.362279098110908e-05, 'epoch': 0.98}\n",
            "{'loss': 0.2638, 'grad_norm': 9.667289733886719, 'learning_rate': 3.354661791590494e-05, 'epoch': 0.99}\n",
            "{'loss': 0.1895, 'grad_norm': 10.131827354431152, 'learning_rate': 3.3470444850700794e-05, 'epoch': 0.99}\n",
            "{'loss': 0.2091, 'grad_norm': 2.2025415897369385, 'learning_rate': 3.339427178549665e-05, 'epoch': 1.0}\n",
            "{'loss': 0.2249, 'grad_norm': 5.4695024490356445, 'learning_rate': 3.331809872029251e-05, 'epoch': 1.0}\n",
            "{'loss': 0.0621, 'grad_norm': 0.7040788531303406, 'learning_rate': 3.324192565508836e-05, 'epoch': 1.01}\n",
            "{'loss': 0.1603, 'grad_norm': 4.518933296203613, 'learning_rate': 3.3165752589884216e-05, 'epoch': 1.01}\n",
            "{'loss': 0.1163, 'grad_norm': 0.715309202671051, 'learning_rate': 3.3089579524680077e-05, 'epoch': 1.01}\n",
            "{'loss': 0.1169, 'grad_norm': 0.06454624235630035, 'learning_rate': 3.301340645947593e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0576, 'grad_norm': 0.675272524356842, 'learning_rate': 3.293723339427179e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0826, 'grad_norm': 0.05259609594941139, 'learning_rate': 3.2861060329067645e-05, 'epoch': 1.03}\n",
            "{'loss': 0.0861, 'grad_norm': 3.6711268424987793, 'learning_rate': 3.27848872638635e-05, 'epoch': 1.03}\n",
            "{'loss': 0.1328, 'grad_norm': 0.7533062100410461, 'learning_rate': 3.270871419865936e-05, 'epoch': 1.04}\n",
            "{'loss': 0.0952, 'grad_norm': 0.04163823649287224, 'learning_rate': 3.263254113345521e-05, 'epoch': 1.04}\n",
            "{'loss': 0.0777, 'grad_norm': 16.096155166625977, 'learning_rate': 3.255636806825107e-05, 'epoch': 1.05}\n",
            "{'loss': 0.216, 'grad_norm': 0.07104230672121048, 'learning_rate': 3.248019500304693e-05, 'epoch': 1.05}\n",
            "{'loss': 0.0583, 'grad_norm': 8.28960132598877, 'learning_rate': 3.240402193784278e-05, 'epoch': 1.06}\n",
            "{'loss': 0.2037, 'grad_norm': 10.69831657409668, 'learning_rate': 3.232784887263864e-05, 'epoch': 1.06}\n",
            "{'loss': 0.1104, 'grad_norm': 7.133384704589844, 'learning_rate': 3.2251675807434496e-05, 'epoch': 1.06}\n",
            "{'loss': 0.1327, 'grad_norm': 12.16053295135498, 'learning_rate': 3.217550274223035e-05, 'epoch': 1.07}\n",
            "{'loss': 0.0513, 'grad_norm': 0.4340890645980835, 'learning_rate': 3.209932967702621e-05, 'epoch': 1.07}\n",
            "{'loss': 0.1901, 'grad_norm': 0.054769132286310196, 'learning_rate': 3.2023156611822064e-05, 'epoch': 1.08}\n",
            "{'loss': 0.0963, 'grad_norm': 6.242935657501221, 'learning_rate': 3.194698354661792e-05, 'epoch': 1.08}\n",
            "{'loss': 0.1431, 'grad_norm': 6.714456081390381, 'learning_rate': 3.187081048141377e-05, 'epoch': 1.09}\n",
            "{'loss': 0.0833, 'grad_norm': 0.31841591000556946, 'learning_rate': 3.1794637416209625e-05, 'epoch': 1.09}\n",
            "{'loss': 0.0633, 'grad_norm': 0.09920436888933182, 'learning_rate': 3.1718464351005486e-05, 'epoch': 1.1}\n",
            "{'loss': 0.1538, 'grad_norm': 11.708529472351074, 'learning_rate': 3.164229128580134e-05, 'epoch': 1.1}\n",
            "{'loss': 0.1945, 'grad_norm': 0.580790102481842, 'learning_rate': 3.1566118220597193e-05, 'epoch': 1.11}\n",
            "{'loss': 0.2131, 'grad_norm': 9.411500930786133, 'learning_rate': 3.1489945155393054e-05, 'epoch': 1.11}\n",
            "{'loss': 0.2471, 'grad_norm': 0.09721101075410843, 'learning_rate': 3.141377209018891e-05, 'epoch': 1.12}\n",
            "{'loss': 0.1896, 'grad_norm': 1.5912389755249023, 'learning_rate': 3.133759902498477e-05, 'epoch': 1.12}\n",
            "{'loss': 0.1148, 'grad_norm': 7.981934070587158, 'learning_rate': 3.126142595978062e-05, 'epoch': 1.12}\n",
            "{'loss': 0.1976, 'grad_norm': 2.196892023086548, 'learning_rate': 3.1185252894576476e-05, 'epoch': 1.13}\n",
            "{'loss': 0.1411, 'grad_norm': 5.31156587600708, 'learning_rate': 3.110907982937234e-05, 'epoch': 1.13}\n",
            "{'loss': 0.2048, 'grad_norm': 7.1495513916015625, 'learning_rate': 3.103290676416819e-05, 'epoch': 1.14}\n",
            "{'loss': 0.0768, 'grad_norm': 7.312055587768555, 'learning_rate': 3.0956733698964044e-05, 'epoch': 1.14}\n",
            "{'loss': 0.1534, 'grad_norm': 0.49263134598731995, 'learning_rate': 3.0880560633759905e-05, 'epoch': 1.15}\n",
            "{'loss': 0.0424, 'grad_norm': 0.3968610465526581, 'learning_rate': 3.080438756855576e-05, 'epoch': 1.15}\n",
            "{'loss': 0.1196, 'grad_norm': 3.588118076324463, 'learning_rate': 3.072821450335161e-05, 'epoch': 1.16}\n",
            "{'loss': 0.1216, 'grad_norm': 12.291637420654297, 'learning_rate': 3.065204143814747e-05, 'epoch': 1.16}\n",
            "{'loss': 0.0732, 'grad_norm': 7.067400932312012, 'learning_rate': 3.057586837294333e-05, 'epoch': 1.17}\n",
            "{'loss': 0.0401, 'grad_norm': 0.6322582960128784, 'learning_rate': 3.0499695307739184e-05, 'epoch': 1.17}\n",
            "{'loss': 0.2056, 'grad_norm': 17.46965980529785, 'learning_rate': 3.042352224253504e-05, 'epoch': 1.17}\n",
            "{'loss': 0.2499, 'grad_norm': 0.3712201416492462, 'learning_rate': 3.03473491773309e-05, 'epoch': 1.18}\n",
            "{'loss': 0.1243, 'grad_norm': 0.1437879204750061, 'learning_rate': 3.0271176112126752e-05, 'epoch': 1.18}\n",
            "{'loss': 0.1412, 'grad_norm': 8.136507034301758, 'learning_rate': 3.019500304692261e-05, 'epoch': 1.19}\n",
            "{'loss': 0.1628, 'grad_norm': 10.819439888000488, 'learning_rate': 3.0118829981718467e-05, 'epoch': 1.19}\n",
            "{'loss': 0.1421, 'grad_norm': 0.326204389333725, 'learning_rate': 3.0042656916514324e-05, 'epoch': 1.2}\n",
            "{'loss': 0.0607, 'grad_norm': 11.609807968139648, 'learning_rate': 2.9966483851310178e-05, 'epoch': 1.2}\n",
            "{'loss': 0.0919, 'grad_norm': 8.901257514953613, 'learning_rate': 2.9890310786106035e-05, 'epoch': 1.21}\n",
            "{'loss': 0.078, 'grad_norm': 1.7877272367477417, 'learning_rate': 2.9814137720901892e-05, 'epoch': 1.21}\n",
            "{'loss': 0.1749, 'grad_norm': 0.07336869835853577, 'learning_rate': 2.973796465569775e-05, 'epoch': 1.22}\n",
            "{'loss': 0.1517, 'grad_norm': 3.2345495223999023, 'learning_rate': 2.9661791590493603e-05, 'epoch': 1.22}\n",
            "{'loss': 0.2023, 'grad_norm': 2.2356724739074707, 'learning_rate': 2.958561852528946e-05, 'epoch': 1.22}\n",
            "{'loss': 0.1678, 'grad_norm': 5.966216087341309, 'learning_rate': 2.9509445460085317e-05, 'epoch': 1.23}\n",
            "{'loss': 0.1311, 'grad_norm': 0.28110530972480774, 'learning_rate': 2.943327239488117e-05, 'epoch': 1.23}\n",
            "{'loss': 0.0972, 'grad_norm': 3.4838004112243652, 'learning_rate': 2.935709932967703e-05, 'epoch': 1.24}\n",
            "{'loss': 0.1393, 'grad_norm': 1.8111740350723267, 'learning_rate': 2.9280926264472886e-05, 'epoch': 1.24}\n",
            "{'loss': 0.2631, 'grad_norm': 3.7410998344421387, 'learning_rate': 2.9204753199268743e-05, 'epoch': 1.25}\n",
            "{'loss': 0.0873, 'grad_norm': 2.685042381286621, 'learning_rate': 2.9128580134064597e-05, 'epoch': 1.25}\n",
            "{'loss': 0.1333, 'grad_norm': 1.4601126909255981, 'learning_rate': 2.9052407068860454e-05, 'epoch': 1.26}\n",
            "{'loss': 0.0707, 'grad_norm': 0.1368579864501953, 'learning_rate': 2.897623400365631e-05, 'epoch': 1.26}\n",
            "{'loss': 0.1466, 'grad_norm': 0.07285112887620926, 'learning_rate': 2.8900060938452168e-05, 'epoch': 1.27}\n",
            "{'loss': 0.0933, 'grad_norm': 11.365248680114746, 'learning_rate': 2.8823887873248022e-05, 'epoch': 1.27}\n",
            "{'loss': 0.1646, 'grad_norm': 2.493652820587158, 'learning_rate': 2.874771480804388e-05, 'epoch': 1.28}\n",
            "{'loss': 0.2109, 'grad_norm': 17.713762283325195, 'learning_rate': 2.8671541742839736e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0806, 'grad_norm': 4.296757221221924, 'learning_rate': 2.8595368677635587e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0319, 'grad_norm': 0.1859969198703766, 'learning_rate': 2.8519195612431444e-05, 'epoch': 1.29}\n",
            "{'loss': 0.1693, 'grad_norm': 0.13007396459579468, 'learning_rate': 2.8443022547227298e-05, 'epoch': 1.29}\n",
            "{'loss': 0.1664, 'grad_norm': 1.8345340490341187, 'learning_rate': 2.8366849482023155e-05, 'epoch': 1.3}\n",
            "{'loss': 0.1468, 'grad_norm': 0.1733209192752838, 'learning_rate': 2.8290676416819012e-05, 'epoch': 1.3}\n",
            "{'loss': 0.0838, 'grad_norm': 0.6008114218711853, 'learning_rate': 2.821450335161487e-05, 'epoch': 1.31}\n",
            "{'loss': 0.0865, 'grad_norm': 5.009951591491699, 'learning_rate': 2.8138330286410723e-05, 'epoch': 1.31}\n",
            "{'loss': 0.1401, 'grad_norm': 10.830945014953613, 'learning_rate': 2.806215722120658e-05, 'epoch': 1.32}\n",
            "{'loss': 0.3041, 'grad_norm': 1.9641647338867188, 'learning_rate': 2.7985984156002438e-05, 'epoch': 1.32}\n",
            "{'loss': 0.1072, 'grad_norm': 0.21668852865695953, 'learning_rate': 2.7909811090798295e-05, 'epoch': 1.33}\n",
            "{'loss': 0.2117, 'grad_norm': 1.9009058475494385, 'learning_rate': 2.783363802559415e-05, 'epoch': 1.33}\n",
            "{'loss': 0.1369, 'grad_norm': 8.355925559997559, 'learning_rate': 2.7757464960390006e-05, 'epoch': 1.33}\n",
            "{'loss': 0.0902, 'grad_norm': 8.967479705810547, 'learning_rate': 2.7681291895185863e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0753, 'grad_norm': 0.2980484068393707, 'learning_rate': 2.760511882998172e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0707, 'grad_norm': 5.705594062805176, 'learning_rate': 2.7528945764777574e-05, 'epoch': 1.35}\n",
            "{'loss': 0.1423, 'grad_norm': 10.604036331176758, 'learning_rate': 2.745277269957343e-05, 'epoch': 1.35}\n",
            "{'loss': 0.1428, 'grad_norm': 12.631650924682617, 'learning_rate': 2.737659963436929e-05, 'epoch': 1.36}\n",
            "{'loss': 0.2083, 'grad_norm': 16.73429298400879, 'learning_rate': 2.7300426569165142e-05, 'epoch': 1.36}\n",
            "{'loss': 0.1748, 'grad_norm': 5.4983930587768555, 'learning_rate': 2.7224253503961e-05, 'epoch': 1.37}\n",
            "{'loss': 0.1634, 'grad_norm': 6.499062538146973, 'learning_rate': 2.7148080438756857e-05, 'epoch': 1.37}\n",
            "{'loss': 0.1312, 'grad_norm': 13.044898986816406, 'learning_rate': 2.7071907373552714e-05, 'epoch': 1.38}\n",
            "{'loss': 0.1299, 'grad_norm': 8.114618301391602, 'learning_rate': 2.6995734308348568e-05, 'epoch': 1.38}\n",
            "{'loss': 0.1239, 'grad_norm': 7.34710168838501, 'learning_rate': 2.6919561243144425e-05, 'epoch': 1.38}\n",
            "{'loss': 0.0549, 'grad_norm': 0.6463066935539246, 'learning_rate': 2.6843388177940282e-05, 'epoch': 1.39}\n",
            "{'loss': 0.0708, 'grad_norm': 3.065742015838623, 'learning_rate': 2.676721511273614e-05, 'epoch': 1.39}\n",
            "{'loss': 0.2192, 'grad_norm': 10.470105171203613, 'learning_rate': 2.6691042047531993e-05, 'epoch': 1.4}\n",
            "{'loss': 0.0993, 'grad_norm': 22.23053741455078, 'learning_rate': 2.661486898232785e-05, 'epoch': 1.4}\n",
            "{'loss': 0.1481, 'grad_norm': 0.09269174933433533, 'learning_rate': 2.6538695917123707e-05, 'epoch': 1.41}\n",
            "{'loss': 0.1818, 'grad_norm': 11.371156692504883, 'learning_rate': 2.6462522851919565e-05, 'epoch': 1.41}\n",
            "{'loss': 0.0849, 'grad_norm': 3.5722320079803467, 'learning_rate': 2.638634978671542e-05, 'epoch': 1.42}\n",
            "{'loss': 0.1046, 'grad_norm': 4.797784805297852, 'learning_rate': 2.6310176721511276e-05, 'epoch': 1.42}\n",
            "{'loss': 0.1279, 'grad_norm': 0.16982658207416534, 'learning_rate': 2.6234003656307133e-05, 'epoch': 1.43}\n",
            "{'loss': 0.1247, 'grad_norm': 15.145465850830078, 'learning_rate': 2.615783059110299e-05, 'epoch': 1.43}\n",
            "{'loss': 0.0911, 'grad_norm': 4.229768753051758, 'learning_rate': 2.6081657525898844e-05, 'epoch': 1.44}\n",
            "{'loss': 0.166, 'grad_norm': 5.491514205932617, 'learning_rate': 2.60054844606947e-05, 'epoch': 1.44}\n",
            "{'loss': 0.1792, 'grad_norm': 4.788753986358643, 'learning_rate': 2.5929311395490558e-05, 'epoch': 1.44}\n",
            "{'loss': 0.1528, 'grad_norm': 5.55245304107666, 'learning_rate': 2.5853138330286415e-05, 'epoch': 1.45}\n",
            "{'loss': 0.1036, 'grad_norm': 9.357393264770508, 'learning_rate': 2.577696526508227e-05, 'epoch': 1.45}\n",
            "{'loss': 0.1098, 'grad_norm': 19.36480712890625, 'learning_rate': 2.5700792199878127e-05, 'epoch': 1.46}\n",
            "{'loss': 0.1529, 'grad_norm': 0.9756605625152588, 'learning_rate': 2.5624619134673984e-05, 'epoch': 1.46}\n",
            "{'loss': 0.077, 'grad_norm': 13.654232025146484, 'learning_rate': 2.5548446069469838e-05, 'epoch': 1.47}\n",
            "{'loss': 0.0849, 'grad_norm': 0.09753354638814926, 'learning_rate': 2.5472273004265695e-05, 'epoch': 1.47}\n",
            "{'loss': 0.1577, 'grad_norm': 17.54581642150879, 'learning_rate': 2.5396099939061552e-05, 'epoch': 1.48}\n",
            "{'loss': 0.1256, 'grad_norm': 3.091505765914917, 'learning_rate': 2.5319926873857402e-05, 'epoch': 1.48}\n",
            "{'loss': 0.1505, 'grad_norm': 21.134260177612305, 'learning_rate': 2.524375380865326e-05, 'epoch': 1.49}\n",
            "{'loss': 0.1198, 'grad_norm': 3.051893949508667, 'learning_rate': 2.5167580743449117e-05, 'epoch': 1.49}\n",
            "{'loss': 0.0533, 'grad_norm': 11.828478813171387, 'learning_rate': 2.509140767824497e-05, 'epoch': 1.49}\n",
            "{'loss': 0.0621, 'grad_norm': 0.2180643230676651, 'learning_rate': 2.5015234613040828e-05, 'epoch': 1.5}\n",
            "{'loss': 0.2032, 'grad_norm': 0.9816933870315552, 'learning_rate': 2.493906154783669e-05, 'epoch': 1.5}\n",
            "{'loss': 0.1765, 'grad_norm': 0.03345417603850365, 'learning_rate': 2.4862888482632542e-05, 'epoch': 1.51}\n",
            "{'loss': 0.0962, 'grad_norm': 0.11594555526971817, 'learning_rate': 2.47867154174284e-05, 'epoch': 1.51}\n",
            "{'loss': 0.1829, 'grad_norm': 0.07308071106672287, 'learning_rate': 2.4710542352224257e-05, 'epoch': 1.52}\n",
            "{'loss': 0.2405, 'grad_norm': 10.460182189941406, 'learning_rate': 2.4634369287020114e-05, 'epoch': 1.52}\n",
            "{'loss': 0.1919, 'grad_norm': 1.0718547105789185, 'learning_rate': 2.4558196221815968e-05, 'epoch': 1.53}\n",
            "{'loss': 0.1485, 'grad_norm': 1.3874949216842651, 'learning_rate': 2.448202315661182e-05, 'epoch': 1.53}\n",
            "{'loss': 0.1538, 'grad_norm': 10.06380558013916, 'learning_rate': 2.440585009140768e-05, 'epoch': 1.54}\n",
            "{'loss': 0.1217, 'grad_norm': 4.692361831665039, 'learning_rate': 2.4329677026203536e-05, 'epoch': 1.54}\n",
            "{'loss': 0.1057, 'grad_norm': 0.47125521302223206, 'learning_rate': 2.425350396099939e-05, 'epoch': 1.54}\n",
            "{'loss': 0.176, 'grad_norm': 0.33684074878692627, 'learning_rate': 2.4177330895795247e-05, 'epoch': 1.55}\n",
            "{'loss': 0.1657, 'grad_norm': 21.404157638549805, 'learning_rate': 2.4101157830591104e-05, 'epoch': 1.55}\n",
            "{'loss': 0.2581, 'grad_norm': 0.44069114327430725, 'learning_rate': 2.402498476538696e-05, 'epoch': 1.56}\n",
            "{'loss': 0.1177, 'grad_norm': 0.14054349064826965, 'learning_rate': 2.3948811700182815e-05, 'epoch': 1.56}\n",
            "{'loss': 0.1107, 'grad_norm': 0.6816719174385071, 'learning_rate': 2.3872638634978672e-05, 'epoch': 1.57}\n",
            "{'loss': 0.1535, 'grad_norm': 13.172555923461914, 'learning_rate': 2.379646556977453e-05, 'epoch': 1.57}\n",
            "{'loss': 0.1229, 'grad_norm': 1.770911455154419, 'learning_rate': 2.3720292504570387e-05, 'epoch': 1.58}\n",
            "{'loss': 0.1154, 'grad_norm': 1.1399457454681396, 'learning_rate': 2.364411943936624e-05, 'epoch': 1.58}\n",
            "{'loss': 0.1261, 'grad_norm': 0.314506471157074, 'learning_rate': 2.3567946374162098e-05, 'epoch': 1.59}\n",
            "{'loss': 0.1321, 'grad_norm': 1.6428108215332031, 'learning_rate': 2.3491773308957955e-05, 'epoch': 1.59}\n",
            "{'loss': 0.1299, 'grad_norm': 0.23088134825229645, 'learning_rate': 2.341560024375381e-05, 'epoch': 1.6}\n",
            "{'loss': 0.2072, 'grad_norm': 11.415205955505371, 'learning_rate': 2.3339427178549666e-05, 'epoch': 1.6}\n",
            "{'loss': 0.0935, 'grad_norm': 0.09772400557994843, 'learning_rate': 2.3263254113345523e-05, 'epoch': 1.6}\n",
            "{'loss': 0.1149, 'grad_norm': 1.7321547269821167, 'learning_rate': 2.318708104814138e-05, 'epoch': 1.61}\n",
            "{'loss': 0.1671, 'grad_norm': 7.893449306488037, 'learning_rate': 2.3110907982937234e-05, 'epoch': 1.61}\n",
            "{'loss': 0.1198, 'grad_norm': 5.535398960113525, 'learning_rate': 2.303473491773309e-05, 'epoch': 1.62}\n",
            "{'loss': 0.1877, 'grad_norm': 12.51246166229248, 'learning_rate': 2.295856185252895e-05, 'epoch': 1.62}\n",
            "{'loss': 0.1735, 'grad_norm': 11.248029708862305, 'learning_rate': 2.2882388787324806e-05, 'epoch': 1.63}\n",
            "{'loss': 0.1425, 'grad_norm': 7.005470275878906, 'learning_rate': 2.280621572212066e-05, 'epoch': 1.63}\n",
            "{'loss': 0.1547, 'grad_norm': 11.796548843383789, 'learning_rate': 2.2730042656916513e-05, 'epoch': 1.64}\n",
            "{'loss': 0.1143, 'grad_norm': 0.41189971566200256, 'learning_rate': 2.265386959171237e-05, 'epoch': 1.64}\n",
            "{'loss': 0.1204, 'grad_norm': 3.1227762699127197, 'learning_rate': 2.2577696526508228e-05, 'epoch': 1.65}\n",
            "{'loss': 0.1918, 'grad_norm': 9.967114448547363, 'learning_rate': 2.2501523461304085e-05, 'epoch': 1.65}\n",
            "{'loss': 0.083, 'grad_norm': 1.5718013048171997, 'learning_rate': 2.242535039609994e-05, 'epoch': 1.65}\n",
            "{'loss': 0.1482, 'grad_norm': 9.549107551574707, 'learning_rate': 2.2349177330895796e-05, 'epoch': 1.66}\n",
            "{'loss': 0.1105, 'grad_norm': 2.1017768383026123, 'learning_rate': 2.2273004265691653e-05, 'epoch': 1.66}\n",
            "{'loss': 0.1253, 'grad_norm': 6.635213375091553, 'learning_rate': 2.2196831200487507e-05, 'epoch': 1.67}\n",
            "{'loss': 0.1408, 'grad_norm': 6.0404133796691895, 'learning_rate': 2.2120658135283364e-05, 'epoch': 1.67}\n",
            "{'loss': 0.0671, 'grad_norm': 0.2856086194515228, 'learning_rate': 2.204448507007922e-05, 'epoch': 1.68}\n",
            "{'loss': 0.0926, 'grad_norm': 0.31044089794158936, 'learning_rate': 2.196831200487508e-05, 'epoch': 1.68}\n",
            "{'loss': 0.0837, 'grad_norm': 19.586139678955078, 'learning_rate': 2.1892138939670932e-05, 'epoch': 1.69}\n",
            "{'loss': 0.1856, 'grad_norm': 1.884035348892212, 'learning_rate': 2.181596587446679e-05, 'epoch': 1.69}\n",
            "{'loss': 0.0589, 'grad_norm': 0.07712983340024948, 'learning_rate': 2.1739792809262647e-05, 'epoch': 1.7}\n",
            "{'loss': 0.2317, 'grad_norm': 9.01064682006836, 'learning_rate': 2.1663619744058504e-05, 'epoch': 1.7}\n",
            "{'loss': 0.1854, 'grad_norm': 7.481130123138428, 'learning_rate': 2.1587446678854358e-05, 'epoch': 1.7}\n",
            "{'loss': 0.0653, 'grad_norm': 0.11316651850938797, 'learning_rate': 2.1511273613650215e-05, 'epoch': 1.71}\n",
            "{'loss': 0.1631, 'grad_norm': 2.6066031455993652, 'learning_rate': 2.1435100548446072e-05, 'epoch': 1.71}\n",
            "{'loss': 0.0716, 'grad_norm': 0.1398427039384842, 'learning_rate': 2.135892748324193e-05, 'epoch': 1.72}\n",
            "{'loss': 0.2389, 'grad_norm': 13.363998413085938, 'learning_rate': 2.1282754418037783e-05, 'epoch': 1.72}\n",
            "{'loss': 0.0991, 'grad_norm': 4.333757400512695, 'learning_rate': 2.1206581352833637e-05, 'epoch': 1.73}\n",
            "{'loss': 0.2155, 'grad_norm': 9.778027534484863, 'learning_rate': 2.1130408287629494e-05, 'epoch': 1.73}\n",
            "{'loss': 0.11, 'grad_norm': 8.043153762817383, 'learning_rate': 2.105423522242535e-05, 'epoch': 1.74}\n",
            "{'loss': 0.0989, 'grad_norm': 0.1532701849937439, 'learning_rate': 2.0978062157221205e-05, 'epoch': 1.74}\n",
            "{'loss': 0.14, 'grad_norm': 0.15942688286304474, 'learning_rate': 2.0901889092017062e-05, 'epoch': 1.75}\n",
            "{'loss': 0.1481, 'grad_norm': 0.12794403731822968, 'learning_rate': 2.082571602681292e-05, 'epoch': 1.75}\n",
            "{'loss': 0.1439, 'grad_norm': 11.145452499389648, 'learning_rate': 2.0749542961608777e-05, 'epoch': 1.76}\n",
            "{'loss': 0.0753, 'grad_norm': 1.4361954927444458, 'learning_rate': 2.067336989640463e-05, 'epoch': 1.76}\n",
            "{'loss': 0.0723, 'grad_norm': 2.545274019241333, 'learning_rate': 2.0597196831200488e-05, 'epoch': 1.76}\n",
            "{'loss': 0.1187, 'grad_norm': 0.13164152204990387, 'learning_rate': 2.0521023765996345e-05, 'epoch': 1.77}\n",
            "{'loss': 0.096, 'grad_norm': 0.11760291457176208, 'learning_rate': 2.0444850700792202e-05, 'epoch': 1.77}\n",
            "{'loss': 0.2083, 'grad_norm': 20.73442268371582, 'learning_rate': 2.0368677635588056e-05, 'epoch': 1.78}\n",
            "{'loss': 0.1089, 'grad_norm': 0.2374720424413681, 'learning_rate': 2.0292504570383913e-05, 'epoch': 1.78}\n",
            "{'loss': 0.1065, 'grad_norm': 0.3377625346183777, 'learning_rate': 2.021633150517977e-05, 'epoch': 1.79}\n",
            "{'loss': 0.0355, 'grad_norm': 13.83339786529541, 'learning_rate': 2.0140158439975627e-05, 'epoch': 1.79}\n",
            "{'loss': 0.1136, 'grad_norm': 1.8292269706726074, 'learning_rate': 2.006398537477148e-05, 'epoch': 1.8}\n",
            "{'loss': 0.1728, 'grad_norm': 25.807350158691406, 'learning_rate': 1.998781230956734e-05, 'epoch': 1.8}\n",
            "{'loss': 0.1021, 'grad_norm': 0.07089213281869888, 'learning_rate': 1.9911639244363196e-05, 'epoch': 1.81}\n",
            "{'loss': 0.1438, 'grad_norm': 6.412554740905762, 'learning_rate': 1.9835466179159053e-05, 'epoch': 1.81}\n",
            "{'loss': 0.1134, 'grad_norm': 11.220894813537598, 'learning_rate': 1.9759293113954907e-05, 'epoch': 1.81}\n",
            "{'loss': 0.052, 'grad_norm': 2.7562947273254395, 'learning_rate': 1.9683120048750764e-05, 'epoch': 1.82}\n",
            "{'loss': 0.1632, 'grad_norm': 17.906660079956055, 'learning_rate': 1.960694698354662e-05, 'epoch': 1.82}\n",
            "{'loss': 0.1672, 'grad_norm': 17.036937713623047, 'learning_rate': 1.9530773918342475e-05, 'epoch': 1.83}\n",
            "{'loss': 0.086, 'grad_norm': 2.6818923950195312, 'learning_rate': 1.945460085313833e-05, 'epoch': 1.83}\n",
            "{'loss': 0.173, 'grad_norm': 0.07802894711494446, 'learning_rate': 1.9378427787934186e-05, 'epoch': 1.84}\n",
            "{'loss': 0.1547, 'grad_norm': 13.121176719665527, 'learning_rate': 1.9302254722730043e-05, 'epoch': 1.84}\n",
            "{'loss': 0.1181, 'grad_norm': 5.468404293060303, 'learning_rate': 1.92260816575259e-05, 'epoch': 1.85}\n",
            "{'loss': 0.1458, 'grad_norm': 3.3400628566741943, 'learning_rate': 1.9149908592321754e-05, 'epoch': 1.85}\n",
            "{'loss': 0.0713, 'grad_norm': 5.604240894317627, 'learning_rate': 1.907373552711761e-05, 'epoch': 1.86}\n",
            "{'loss': 0.1431, 'grad_norm': 14.811323165893555, 'learning_rate': 1.899756246191347e-05, 'epoch': 1.86}\n",
            "{'loss': 0.2186, 'grad_norm': 2.1553447246551514, 'learning_rate': 1.8921389396709326e-05, 'epoch': 1.86}\n",
            "{'loss': 0.0814, 'grad_norm': 0.38152050971984863, 'learning_rate': 1.884521633150518e-05, 'epoch': 1.87}\n",
            "{'loss': 0.1243, 'grad_norm': 3.2369110584259033, 'learning_rate': 1.8769043266301037e-05, 'epoch': 1.87}\n",
            "{'loss': 0.1764, 'grad_norm': 6.32411003112793, 'learning_rate': 1.8692870201096894e-05, 'epoch': 1.88}\n",
            "{'loss': 0.1873, 'grad_norm': 0.2938353717327118, 'learning_rate': 1.861669713589275e-05, 'epoch': 1.88}\n",
            "{'loss': 0.1612, 'grad_norm': 11.231101989746094, 'learning_rate': 1.8540524070688605e-05, 'epoch': 1.89}\n",
            "{'loss': 0.0942, 'grad_norm': 12.615586280822754, 'learning_rate': 1.8464351005484462e-05, 'epoch': 1.89}\n",
            "{'loss': 0.0771, 'grad_norm': 6.377898693084717, 'learning_rate': 1.838817794028032e-05, 'epoch': 1.9}\n",
            "{'loss': 0.1008, 'grad_norm': 0.1770457923412323, 'learning_rate': 1.8312004875076173e-05, 'epoch': 1.9}\n",
            "{'loss': 0.1959, 'grad_norm': 3.367600440979004, 'learning_rate': 1.823583180987203e-05, 'epoch': 1.91}\n",
            "{'loss': 0.1975, 'grad_norm': 0.583580493927002, 'learning_rate': 1.8159658744667887e-05, 'epoch': 1.91}\n",
            "{'loss': 0.1341, 'grad_norm': 1.3662630319595337, 'learning_rate': 1.8083485679463745e-05, 'epoch': 1.91}\n",
            "{'loss': 0.1019, 'grad_norm': 2.1347219944000244, 'learning_rate': 1.80073126142596e-05, 'epoch': 1.92}\n",
            "{'loss': 0.1127, 'grad_norm': 7.736536979675293, 'learning_rate': 1.7931139549055456e-05, 'epoch': 1.92}\n",
            "{'loss': 0.1533, 'grad_norm': 12.113482475280762, 'learning_rate': 1.785496648385131e-05, 'epoch': 1.93}\n",
            "{'loss': 0.1571, 'grad_norm': 0.09763213992118835, 'learning_rate': 1.7778793418647167e-05, 'epoch': 1.93}\n",
            "{'loss': 0.1335, 'grad_norm': 5.875694274902344, 'learning_rate': 1.7702620353443024e-05, 'epoch': 1.94}\n",
            "{'loss': 0.0311, 'grad_norm': 0.19968409836292267, 'learning_rate': 1.7626447288238878e-05, 'epoch': 1.94}\n",
            "{'loss': 0.0753, 'grad_norm': 0.586086094379425, 'learning_rate': 1.7550274223034735e-05, 'epoch': 1.95}\n",
            "{'loss': 0.2063, 'grad_norm': 0.12998516857624054, 'learning_rate': 1.7474101157830592e-05, 'epoch': 1.95}\n",
            "{'loss': 0.0884, 'grad_norm': 0.9020131230354309, 'learning_rate': 1.739792809262645e-05, 'epoch': 1.96}\n",
            "{'loss': 0.1738, 'grad_norm': 0.3821214437484741, 'learning_rate': 1.7321755027422303e-05, 'epoch': 1.96}\n",
            "{'loss': 0.2438, 'grad_norm': 2.8902955055236816, 'learning_rate': 1.724558196221816e-05, 'epoch': 1.97}\n",
            "{'loss': 0.1101, 'grad_norm': 0.21473415195941925, 'learning_rate': 1.7169408897014017e-05, 'epoch': 1.97}\n",
            "{'loss': 0.1439, 'grad_norm': 0.25248196721076965, 'learning_rate': 1.709323583180987e-05, 'epoch': 1.97}\n",
            "{'loss': 0.0999, 'grad_norm': 13.644766807556152, 'learning_rate': 1.701706276660573e-05, 'epoch': 1.98}\n",
            "{'loss': 0.1187, 'grad_norm': 4.905945777893066, 'learning_rate': 1.6940889701401586e-05, 'epoch': 1.98}\n",
            "{'loss': 0.1312, 'grad_norm': 4.701362609863281, 'learning_rate': 1.6864716636197443e-05, 'epoch': 1.99}\n",
            "{'loss': 0.091, 'grad_norm': 9.085670471191406, 'learning_rate': 1.6788543570993297e-05, 'epoch': 1.99}\n",
            "{'loss': 0.1036, 'grad_norm': 12.782740592956543, 'learning_rate': 1.6712370505789154e-05, 'epoch': 2.0}\n",
            "{'loss': 0.1125, 'grad_norm': 0.4468446969985962, 'learning_rate': 1.663619744058501e-05, 'epoch': 2.0}\n",
            "{'loss': 0.0563, 'grad_norm': 0.4924412667751312, 'learning_rate': 1.6560024375380868e-05, 'epoch': 2.01}\n",
            "{'loss': 0.1016, 'grad_norm': 0.056635018438100815, 'learning_rate': 1.6483851310176722e-05, 'epoch': 2.01}\n",
            "{'loss': 0.0061, 'grad_norm': 0.0675918385386467, 'learning_rate': 1.640767824497258e-05, 'epoch': 2.02}\n",
            "{'loss': 0.1076, 'grad_norm': 5.246110916137695, 'learning_rate': 1.6331505179768436e-05, 'epoch': 2.02}\n",
            "{'loss': 0.0686, 'grad_norm': 3.0759873390197754, 'learning_rate': 1.625533211456429e-05, 'epoch': 2.02}\n",
            "{'loss': 0.0756, 'grad_norm': 0.08248703181743622, 'learning_rate': 1.6179159049360147e-05, 'epoch': 2.03}\n",
            "{'loss': 0.0446, 'grad_norm': 19.671897888183594, 'learning_rate': 1.6102985984156e-05, 'epoch': 2.03}\n",
            "{'loss': 0.0421, 'grad_norm': 11.926542282104492, 'learning_rate': 1.602681291895186e-05, 'epoch': 2.04}\n",
            "{'loss': 0.1103, 'grad_norm': 0.13828454911708832, 'learning_rate': 1.5950639853747716e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0078, 'grad_norm': 0.07335083186626434, 'learning_rate': 1.587446678854357e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0209, 'grad_norm': 1.738160252571106, 'learning_rate': 1.5798293723339427e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0196, 'grad_norm': 0.040426962077617645, 'learning_rate': 1.5722120658135284e-05, 'epoch': 2.06}\n",
            "{'loss': 0.064, 'grad_norm': 0.04560310021042824, 'learning_rate': 1.564594759293114e-05, 'epoch': 2.06}\n",
            "{'loss': 0.0647, 'grad_norm': 0.025359952822327614, 'learning_rate': 1.5569774527726995e-05, 'epoch': 2.07}\n",
            "{'loss': 0.0527, 'grad_norm': 1.1533091068267822, 'learning_rate': 1.5493601462522852e-05, 'epoch': 2.07}\n",
            "{'loss': 0.0726, 'grad_norm': 0.12817195057868958, 'learning_rate': 1.541742839731871e-05, 'epoch': 2.07}\n",
            "{'loss': 0.0728, 'grad_norm': 0.0637984350323677, 'learning_rate': 1.5341255332114566e-05, 'epoch': 2.08}\n",
            "{'loss': 0.0166, 'grad_norm': 0.13806623220443726, 'learning_rate': 1.526508226691042e-05, 'epoch': 2.08}\n",
            "{'loss': 0.0652, 'grad_norm': 0.06808779388666153, 'learning_rate': 1.5188909201706277e-05, 'epoch': 2.09}\n",
            "{'loss': 0.0033, 'grad_norm': 0.026234963908791542, 'learning_rate': 1.5112736136502135e-05, 'epoch': 2.09}\n",
            "{'loss': 0.193, 'grad_norm': 0.01716979406774044, 'learning_rate': 1.503656307129799e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0397, 'grad_norm': 0.02924373559653759, 'learning_rate': 1.4960390006093847e-05, 'epoch': 2.1}\n",
            "{'loss': 0.0706, 'grad_norm': 0.12169662863016129, 'learning_rate': 1.4884216940889703e-05, 'epoch': 2.11}\n",
            "{'loss': 0.0337, 'grad_norm': 0.043368950486183167, 'learning_rate': 1.480804387568556e-05, 'epoch': 2.11}\n",
            "{'loss': 0.1806, 'grad_norm': 0.07564569264650345, 'learning_rate': 1.4731870810481416e-05, 'epoch': 2.12}\n",
            "{'loss': 0.0534, 'grad_norm': 2.1098217964172363, 'learning_rate': 1.4655697745277273e-05, 'epoch': 2.12}\n",
            "{'loss': 0.1497, 'grad_norm': 0.28272193670272827, 'learning_rate': 1.4579524680073125e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0827, 'grad_norm': 0.2662246823310852, 'learning_rate': 1.4503351614868982e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0037, 'grad_norm': 0.06818307191133499, 'learning_rate': 1.4427178549664838e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0368, 'grad_norm': 0.022041724994778633, 'learning_rate': 1.4351005484460695e-05, 'epoch': 2.14}\n",
            "{'loss': 0.0974, 'grad_norm': 0.21019358932971954, 'learning_rate': 1.427483241925655e-05, 'epoch': 2.14}\n",
            "{'loss': 0.0502, 'grad_norm': 0.05785925313830376, 'learning_rate': 1.4198659354052407e-05, 'epoch': 2.15}\n",
            "{'loss': 0.0598, 'grad_norm': 0.04993551969528198, 'learning_rate': 1.4122486288848263e-05, 'epoch': 2.15}\n",
            "{'loss': 0.0329, 'grad_norm': 0.09879621118307114, 'learning_rate': 1.404631322364412e-05, 'epoch': 2.16}\n",
            "{'loss': 0.0322, 'grad_norm': 0.03322647511959076, 'learning_rate': 1.3970140158439976e-05, 'epoch': 2.16}\n",
            "{'loss': 0.06, 'grad_norm': 0.16575932502746582, 'learning_rate': 1.3893967093235833e-05, 'epoch': 2.17}\n",
            "{'loss': 0.0699, 'grad_norm': 0.0722644105553627, 'learning_rate': 1.3817794028031688e-05, 'epoch': 2.17}\n",
            "{'loss': 0.0096, 'grad_norm': 0.041696831583976746, 'learning_rate': 1.3741620962827546e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0026, 'grad_norm': 0.5121824741363525, 'learning_rate': 1.3665447897623401e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0548, 'grad_norm': 0.6777378916740417, 'learning_rate': 1.3589274832419258e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0693, 'grad_norm': 0.17118142545223236, 'learning_rate': 1.3513101767215114e-05, 'epoch': 2.19}\n",
            "{'loss': 0.095, 'grad_norm': 3.011326789855957, 'learning_rate': 1.3436928702010971e-05, 'epoch': 2.19}\n",
            "{'loss': 0.058, 'grad_norm': 0.13403795659542084, 'learning_rate': 1.3360755636806826e-05, 'epoch': 2.2}\n",
            "{'loss': 0.0024, 'grad_norm': 0.04169514402747154, 'learning_rate': 1.3284582571602684e-05, 'epoch': 2.2}\n",
            "{'loss': 0.0722, 'grad_norm': 2.8532192707061768, 'learning_rate': 1.320840950639854e-05, 'epoch': 2.21}\n",
            "{'loss': 0.0124, 'grad_norm': 0.06494436413049698, 'learning_rate': 1.3132236441194395e-05, 'epoch': 2.21}\n",
            "{'loss': 0.0251, 'grad_norm': 0.16916023194789886, 'learning_rate': 1.3056063375990252e-05, 'epoch': 2.22}\n",
            "{'loss': 0.0066, 'grad_norm': 0.036537788808345795, 'learning_rate': 1.2979890310786106e-05, 'epoch': 2.22}\n",
            "{'loss': 0.065, 'grad_norm': 20.065166473388672, 'learning_rate': 1.2903717245581961e-05, 'epoch': 2.23}\n",
            "{'loss': 0.072, 'grad_norm': 4.602805137634277, 'learning_rate': 1.2827544180377818e-05, 'epoch': 2.23}\n",
            "{'loss': 0.1057, 'grad_norm': 0.06596897542476654, 'learning_rate': 1.2751371115173674e-05, 'epoch': 2.23}\n",
            "{'loss': 0.1459, 'grad_norm': 5.329841613769531, 'learning_rate': 1.2675198049969531e-05, 'epoch': 2.24}\n",
            "{'loss': 0.044, 'grad_norm': 0.056855518370866776, 'learning_rate': 1.2599024984765387e-05, 'epoch': 2.24}\n",
            "{'loss': 0.0132, 'grad_norm': 0.11112284660339355, 'learning_rate': 1.2522851919561244e-05, 'epoch': 2.25}\n",
            "{'loss': 0.0323, 'grad_norm': 0.17986823618412018, 'learning_rate': 1.24466788543571e-05, 'epoch': 2.25}\n",
            "{'loss': 0.0807, 'grad_norm': 0.7900922298431396, 'learning_rate': 1.2370505789152956e-05, 'epoch': 2.26}\n",
            "{'loss': 0.0758, 'grad_norm': 0.0695996880531311, 'learning_rate': 1.2294332723948812e-05, 'epoch': 2.26}\n",
            "{'loss': 0.0192, 'grad_norm': 0.12065966427326202, 'learning_rate': 1.221815965874467e-05, 'epoch': 2.27}\n",
            "{'loss': 0.0834, 'grad_norm': 0.2703387439250946, 'learning_rate': 1.2141986593540525e-05, 'epoch': 2.27}\n",
            "{'loss': 0.0834, 'grad_norm': 1.1300417184829712, 'learning_rate': 1.206581352833638e-05, 'epoch': 2.28}\n",
            "{'loss': 0.1179, 'grad_norm': 9.714045524597168, 'learning_rate': 1.1989640463132237e-05, 'epoch': 2.28}\n",
            "{'loss': 0.0242, 'grad_norm': 0.14815948903560638, 'learning_rate': 1.1913467397928093e-05, 'epoch': 2.29}\n",
            "{'loss': 0.0025, 'grad_norm': 0.019190160557627678, 'learning_rate': 1.183729433272395e-05, 'epoch': 2.29}\n",
            "{'loss': 0.0042, 'grad_norm': 0.11409115791320801, 'learning_rate': 1.1761121267519806e-05, 'epoch': 2.29}\n",
            "{'loss': 0.052, 'grad_norm': 0.03998894989490509, 'learning_rate': 1.1684948202315661e-05, 'epoch': 2.3}\n",
            "{'loss': 0.075, 'grad_norm': 0.11744377762079239, 'learning_rate': 1.1608775137111518e-05, 'epoch': 2.3}\n",
            "{'loss': 0.0337, 'grad_norm': 0.04012957587838173, 'learning_rate': 1.1532602071907374e-05, 'epoch': 2.31}\n",
            "{'loss': 0.0347, 'grad_norm': 0.028285659849643707, 'learning_rate': 1.145642900670323e-05, 'epoch': 2.31}\n",
            "{'loss': 0.079, 'grad_norm': 6.329042911529541, 'learning_rate': 1.1380255941499086e-05, 'epoch': 2.32}\n",
            "{'loss': 0.0864, 'grad_norm': 0.05320235341787338, 'learning_rate': 1.1304082876294942e-05, 'epoch': 2.32}\n",
            "{'loss': 0.0322, 'grad_norm': 0.11031822860240936, 'learning_rate': 1.12279098110908e-05, 'epoch': 2.33}\n",
            "{'loss': 0.0017, 'grad_norm': 0.09755026549100876, 'learning_rate': 1.1151736745886655e-05, 'epoch': 2.33}\n",
            "{'loss': 0.0752, 'grad_norm': 0.06273260712623596, 'learning_rate': 1.1075563680682512e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0024, 'grad_norm': 0.03906824439764023, 'learning_rate': 1.0999390615478367e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0719, 'grad_norm': 3.0520896911621094, 'learning_rate': 1.0923217550274223e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0022, 'grad_norm': 0.19478631019592285, 'learning_rate': 1.0847044485070078e-05, 'epoch': 2.35}\n",
            "{'loss': 0.1012, 'grad_norm': 28.23687171936035, 'learning_rate': 1.0770871419865936e-05, 'epoch': 2.35}\n",
            "{'loss': 0.1105, 'grad_norm': 0.05335593968629837, 'learning_rate': 1.0694698354661791e-05, 'epoch': 2.36}\n",
            "{'loss': 0.0522, 'grad_norm': 0.06636495143175125, 'learning_rate': 1.0618525289457648e-05, 'epoch': 2.36}\n",
            "{'loss': 0.0517, 'grad_norm': 0.10537633299827576, 'learning_rate': 1.0542352224253504e-05, 'epoch': 2.37}\n",
            "{'loss': 0.0429, 'grad_norm': 0.05024554580450058, 'learning_rate': 1.0466179159049361e-05, 'epoch': 2.37}\n",
            "{'loss': 0.0472, 'grad_norm': 39.99631881713867, 'learning_rate': 1.0390006093845217e-05, 'epoch': 2.38}\n",
            "{'loss': 0.0854, 'grad_norm': 0.0361163467168808, 'learning_rate': 1.0313833028641074e-05, 'epoch': 2.38}\n",
            "{'loss': 0.0499, 'grad_norm': 0.06439258903265, 'learning_rate': 1.023765996343693e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0025, 'grad_norm': 0.1056845486164093, 'learning_rate': 1.0161486898232786e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0133, 'grad_norm': 0.036044906824827194, 'learning_rate': 1.008531383302864e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0778, 'grad_norm': 12.625940322875977, 'learning_rate': 1.0009140767824497e-05, 'epoch': 2.4}\n",
            "{'loss': 0.0192, 'grad_norm': 0.08049555122852325, 'learning_rate': 9.932967702620353e-06, 'epoch': 2.4}\n",
            "{'loss': 0.0021, 'grad_norm': 0.024158239364624023, 'learning_rate': 9.85679463741621e-06, 'epoch': 2.41}\n",
            "{'loss': 0.0016, 'grad_norm': 0.02164803445339203, 'learning_rate': 9.780621572212066e-06, 'epoch': 2.41}\n",
            "{'loss': 0.0941, 'grad_norm': 0.04405990242958069, 'learning_rate': 9.704448507007923e-06, 'epoch': 2.42}\n",
            "{'loss': 0.1007, 'grad_norm': 0.03671521693468094, 'learning_rate': 9.628275441803778e-06, 'epoch': 2.42}\n",
            "{'loss': 0.0675, 'grad_norm': 2.1095502376556396, 'learning_rate': 9.552102376599636e-06, 'epoch': 2.43}\n",
            "{'loss': 0.1444, 'grad_norm': 17.05965805053711, 'learning_rate': 9.475929311395491e-06, 'epoch': 2.43}\n",
            "{'loss': 0.0813, 'grad_norm': 0.06442436575889587, 'learning_rate': 9.399756246191348e-06, 'epoch': 2.44}\n",
            "{'loss': 0.0557, 'grad_norm': 30.07633399963379, 'learning_rate': 9.323583180987204e-06, 'epoch': 2.44}\n",
            "{'loss': 0.0433, 'grad_norm': 0.028646908700466156, 'learning_rate': 9.24741011578306e-06, 'epoch': 2.45}\n",
            "{'loss': 0.0885, 'grad_norm': 0.04253043234348297, 'learning_rate': 9.171237050578915e-06, 'epoch': 2.45}\n",
            "{'loss': 0.144, 'grad_norm': 23.02127456665039, 'learning_rate': 9.095063985374772e-06, 'epoch': 2.45}\n",
            "{'loss': 0.0726, 'grad_norm': 17.582712173461914, 'learning_rate': 9.018890920170627e-06, 'epoch': 2.46}\n",
            "{'loss': 0.081, 'grad_norm': 0.1418042778968811, 'learning_rate': 8.942717854966485e-06, 'epoch': 2.46}\n",
            "{'loss': 0.0752, 'grad_norm': 0.28570103645324707, 'learning_rate': 8.86654478976234e-06, 'epoch': 2.47}\n",
            "{'loss': 0.0555, 'grad_norm': 0.07121749222278595, 'learning_rate': 8.790371724558197e-06, 'epoch': 2.47}\n",
            "{'loss': 0.0635, 'grad_norm': 0.07491593807935715, 'learning_rate': 8.714198659354053e-06, 'epoch': 2.48}\n",
            "{'loss': 0.0466, 'grad_norm': 0.3134642243385315, 'learning_rate': 8.63802559414991e-06, 'epoch': 2.48}\n",
            "{'loss': 0.0031, 'grad_norm': 0.17178328335285187, 'learning_rate': 8.561852528945766e-06, 'epoch': 2.49}\n",
            "{'loss': 0.0706, 'grad_norm': 1.1207293272018433, 'learning_rate': 8.485679463741623e-06, 'epoch': 2.49}\n",
            "{'loss': 0.0839, 'grad_norm': 19.114904403686523, 'learning_rate': 8.409506398537477e-06, 'epoch': 2.5}\n",
            "{'loss': 0.0402, 'grad_norm': 1.155007004737854, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n",
            "{'loss': 0.084, 'grad_norm': 8.285799980163574, 'learning_rate': 8.25716026812919e-06, 'epoch': 2.5}\n",
            "{'loss': 0.0383, 'grad_norm': 0.3115284740924835, 'learning_rate': 8.180987202925046e-06, 'epoch': 2.51}\n",
            "{'loss': 0.0923, 'grad_norm': 2.2796013355255127, 'learning_rate': 8.104814137720902e-06, 'epoch': 2.51}\n",
            "{'loss': 0.0279, 'grad_norm': 0.17433130741119385, 'learning_rate': 8.028641072516759e-06, 'epoch': 2.52}\n",
            "{'loss': 0.0527, 'grad_norm': 0.19151785969734192, 'learning_rate': 7.952468007312615e-06, 'epoch': 2.52}\n",
            "{'loss': 0.0392, 'grad_norm': 0.07672335207462311, 'learning_rate': 7.876294942108472e-06, 'epoch': 2.53}\n",
            "{'loss': 0.0405, 'grad_norm': 0.3313576877117157, 'learning_rate': 7.800121876904327e-06, 'epoch': 2.53}\n",
            "{'loss': 0.0774, 'grad_norm': 0.039151016622781754, 'learning_rate': 7.723948811700185e-06, 'epoch': 2.54}\n",
            "{'loss': 0.0258, 'grad_norm': 0.05217387527227402, 'learning_rate': 7.647775746496038e-06, 'epoch': 2.54}\n",
            "{'loss': 0.0121, 'grad_norm': 0.020616764202713966, 'learning_rate': 7.571602681291895e-06, 'epoch': 2.55}\n",
            "{'loss': 0.0416, 'grad_norm': 0.050260934978723526, 'learning_rate': 7.495429616087751e-06, 'epoch': 2.55}\n",
            "{'loss': 0.0427, 'grad_norm': 0.07744865864515305, 'learning_rate': 7.419256550883607e-06, 'epoch': 2.55}\n",
            "{'loss': 0.0017, 'grad_norm': 0.036431003361940384, 'learning_rate': 7.343083485679464e-06, 'epoch': 2.56}\n",
            "{'loss': 0.0039, 'grad_norm': 6.090160846710205, 'learning_rate': 7.26691042047532e-06, 'epoch': 2.56}\n",
            "{'loss': 0.1075, 'grad_norm': 46.4681282043457, 'learning_rate': 7.1907373552711764e-06, 'epoch': 2.57}\n",
            "{'loss': 0.049, 'grad_norm': 0.13847579061985016, 'learning_rate': 7.114564290067033e-06, 'epoch': 2.57}\n",
            "{'loss': 0.1244, 'grad_norm': 0.13971778750419617, 'learning_rate': 7.038391224862889e-06, 'epoch': 2.58}\n",
            "{'loss': 0.0221, 'grad_norm': 0.09327402710914612, 'learning_rate': 6.9622181596587455e-06, 'epoch': 2.58}\n",
            "{'loss': 0.0682, 'grad_norm': 8.883801460266113, 'learning_rate': 6.886045094454602e-06, 'epoch': 2.59}\n",
            "{'loss': 0.0125, 'grad_norm': 24.6259765625, 'learning_rate': 6.8098720292504565e-06, 'epoch': 2.59}\n",
            "{'loss': 0.133, 'grad_norm': 0.050612252205610275, 'learning_rate': 6.733698964046313e-06, 'epoch': 2.6}\n",
            "{'loss': 0.0578, 'grad_norm': 0.11705905944108963, 'learning_rate': 6.657525898842169e-06, 'epoch': 2.6}\n",
            "{'loss': 0.0153, 'grad_norm': 0.039257969707250595, 'learning_rate': 6.5813528336380256e-06, 'epoch': 2.61}\n",
            "{'loss': 0.109, 'grad_norm': 0.40486738085746765, 'learning_rate': 6.505179768433882e-06, 'epoch': 2.61}\n",
            "{'loss': 0.1007, 'grad_norm': 0.6660775542259216, 'learning_rate': 6.429006703229738e-06, 'epoch': 2.61}\n",
            "{'loss': 0.0809, 'grad_norm': 0.049871645867824554, 'learning_rate': 6.352833638025595e-06, 'epoch': 2.62}\n",
            "{'loss': 0.0476, 'grad_norm': 1.7098493576049805, 'learning_rate': 6.276660572821451e-06, 'epoch': 2.62}\n",
            "{'loss': 0.0814, 'grad_norm': 0.7906103730201721, 'learning_rate': 6.2004875076173065e-06, 'epoch': 2.63}\n",
            "{'loss': 0.0205, 'grad_norm': 0.3737584352493286, 'learning_rate': 6.124314442413163e-06, 'epoch': 2.63}\n",
            "{'loss': 0.0105, 'grad_norm': 0.21416454017162323, 'learning_rate': 6.048141377209019e-06, 'epoch': 2.64}\n",
            "{'loss': 0.0801, 'grad_norm': 5.165607452392578, 'learning_rate': 5.9719683120048755e-06, 'epoch': 2.64}\n",
            "{'loss': 0.0029, 'grad_norm': 0.032565727829933167, 'learning_rate': 5.895795246800732e-06, 'epoch': 2.65}\n",
            "{'loss': 0.0026, 'grad_norm': 0.032045356929302216, 'learning_rate': 5.819622181596588e-06, 'epoch': 2.65}\n",
            "{'loss': 0.0417, 'grad_norm': 0.02587195672094822, 'learning_rate': 5.743449116392444e-06, 'epoch': 2.66}\n",
            "{'loss': 0.0703, 'grad_norm': 0.04538366571068764, 'learning_rate': 5.6672760511883e-06, 'epoch': 2.66}\n",
            "{'loss': 0.008, 'grad_norm': 0.025201233103871346, 'learning_rate': 5.591102985984156e-06, 'epoch': 2.66}\n",
            "{'loss': 0.0591, 'grad_norm': 8.491387367248535, 'learning_rate': 5.514929920780013e-06, 'epoch': 2.67}\n",
            "{'loss': 0.0184, 'grad_norm': 12.881118774414062, 'learning_rate': 5.438756855575869e-06, 'epoch': 2.67}\n",
            "{'loss': 0.0734, 'grad_norm': 49.89336395263672, 'learning_rate': 5.362583790371725e-06, 'epoch': 2.68}\n",
            "{'loss': 0.0368, 'grad_norm': 0.026266038417816162, 'learning_rate': 5.286410725167581e-06, 'epoch': 2.68}\n",
            "{'loss': 0.0844, 'grad_norm': 14.695971488952637, 'learning_rate': 5.210237659963437e-06, 'epoch': 2.69}\n",
            "{'loss': 0.0193, 'grad_norm': 0.04291676729917526, 'learning_rate': 5.134064594759294e-06, 'epoch': 2.69}\n",
            "{'loss': 0.037, 'grad_norm': 5.8425211906433105, 'learning_rate': 5.05789152955515e-06, 'epoch': 2.7}\n",
            "{'loss': 0.033, 'grad_norm': 2.215820789337158, 'learning_rate': 4.981718464351006e-06, 'epoch': 2.7}\n",
            "{'loss': 0.1536, 'grad_norm': 0.03526141121983528, 'learning_rate': 4.905545399146862e-06, 'epoch': 2.71}\n",
            "{'loss': 0.0014, 'grad_norm': 0.08980691432952881, 'learning_rate': 4.829372333942718e-06, 'epoch': 2.71}\n",
            "{'loss': 0.0465, 'grad_norm': 0.031838782131671906, 'learning_rate': 4.753199268738575e-06, 'epoch': 2.71}\n",
            "{'loss': 0.0235, 'grad_norm': 0.17580434679985046, 'learning_rate': 4.677026203534431e-06, 'epoch': 2.72}\n",
            "{'loss': 0.0866, 'grad_norm': 0.03631962835788727, 'learning_rate': 4.600853138330287e-06, 'epoch': 2.72}\n",
            "{'loss': 0.0524, 'grad_norm': 0.130811408162117, 'learning_rate': 4.524680073126143e-06, 'epoch': 2.73}\n",
            "{'loss': 0.0865, 'grad_norm': 0.03742258623242378, 'learning_rate': 4.448507007921999e-06, 'epoch': 2.73}\n",
            "{'loss': 0.095, 'grad_norm': 4.977554798126221, 'learning_rate': 4.3723339427178555e-06, 'epoch': 2.74}\n",
            "{'loss': 0.0234, 'grad_norm': 0.15701423585414886, 'learning_rate': 4.296160877513712e-06, 'epoch': 2.74}\n",
            "{'loss': 0.0203, 'grad_norm': 0.03237443417310715, 'learning_rate': 4.219987812309568e-06, 'epoch': 2.75}\n",
            "{'loss': 0.0082, 'grad_norm': 22.506423950195312, 'learning_rate': 4.143814747105424e-06, 'epoch': 2.75}\n",
            "{'loss': 0.0715, 'grad_norm': 0.054079148918390274, 'learning_rate': 4.06764168190128e-06, 'epoch': 2.76}\n",
            "{'loss': 0.0014, 'grad_norm': 0.03309285268187523, 'learning_rate': 3.991468616697136e-06, 'epoch': 2.76}\n",
            "{'loss': 0.025, 'grad_norm': 6.12078332901001, 'learning_rate': 3.915295551492993e-06, 'epoch': 2.77}\n",
            "{'loss': 0.0014, 'grad_norm': 0.1717267483472824, 'learning_rate': 3.839122486288848e-06, 'epoch': 2.77}\n",
            "{'loss': 0.0524, 'grad_norm': 0.0477856881916523, 'learning_rate': 3.762949421084705e-06, 'epoch': 2.77}\n",
            "{'loss': 0.0487, 'grad_norm': 0.2985011339187622, 'learning_rate': 3.6867763558805605e-06, 'epoch': 2.78}\n",
            "{'loss': 0.0459, 'grad_norm': 0.028178244829177856, 'learning_rate': 3.610603290676417e-06, 'epoch': 2.78}\n",
            "{'loss': 0.002, 'grad_norm': 0.03876904770731926, 'learning_rate': 3.5344302254722732e-06, 'epoch': 2.79}\n",
            "{'loss': 0.053, 'grad_norm': 0.026851078495383263, 'learning_rate': 3.4582571602681296e-06, 'epoch': 2.79}\n",
            "{'loss': 0.0034, 'grad_norm': 0.01930365338921547, 'learning_rate': 3.382084095063986e-06, 'epoch': 2.8}\n",
            "{'loss': 0.0812, 'grad_norm': 0.10741671919822693, 'learning_rate': 3.3059110298598414e-06, 'epoch': 2.8}\n",
            "{'loss': 0.0169, 'grad_norm': 0.3540058732032776, 'learning_rate': 3.2297379646556978e-06, 'epoch': 2.81}\n",
            "{'loss': 0.0263, 'grad_norm': 0.039636459201574326, 'learning_rate': 3.153564899451554e-06, 'epoch': 2.81}\n",
            "{'loss': 0.0469, 'grad_norm': 0.028202787041664124, 'learning_rate': 3.0773918342474105e-06, 'epoch': 2.82}\n",
            "{'loss': 0.0318, 'grad_norm': 0.3782081604003906, 'learning_rate': 3.0012187690432664e-06, 'epoch': 2.82}\n",
            "{'loss': 0.045, 'grad_norm': 0.014049312099814415, 'learning_rate': 2.9250457038391228e-06, 'epoch': 2.82}\n",
            "{'loss': 0.0455, 'grad_norm': 0.024807658046483994, 'learning_rate': 2.848872638634979e-06, 'epoch': 2.83}\n",
            "{'loss': 0.0627, 'grad_norm': 0.027115410193800926, 'learning_rate': 2.772699573430835e-06, 'epoch': 2.83}\n",
            "{'loss': 0.0403, 'grad_norm': 3.7688848972320557, 'learning_rate': 2.6965265082266914e-06, 'epoch': 2.84}\n",
            "{'loss': 0.0829, 'grad_norm': 0.03779749572277069, 'learning_rate': 2.6203534430225473e-06, 'epoch': 2.84}\n",
            "{'loss': 0.0018, 'grad_norm': 0.038460128009319305, 'learning_rate': 2.5441803778184037e-06, 'epoch': 2.85}\n",
            "{'loss': 0.0017, 'grad_norm': 0.018975242972373962, 'learning_rate': 2.4680073126142596e-06, 'epoch': 2.85}\n",
            "{'loss': 0.0972, 'grad_norm': 0.7253327965736389, 'learning_rate': 2.391834247410116e-06, 'epoch': 2.86}\n",
            "{'loss': 0.0657, 'grad_norm': 22.087554931640625, 'learning_rate': 2.315661182205972e-06, 'epoch': 2.86}\n",
            "{'loss': 0.0031, 'grad_norm': 0.08290884643793106, 'learning_rate': 2.239488117001828e-06, 'epoch': 2.87}\n",
            "{'loss': 0.0894, 'grad_norm': 14.634119033813477, 'learning_rate': 2.163315051797684e-06, 'epoch': 2.87}\n",
            "{'loss': 0.0395, 'grad_norm': 0.03522948920726776, 'learning_rate': 2.0871419865935405e-06, 'epoch': 2.87}\n",
            "{'loss': 0.0432, 'grad_norm': 5.016549110412598, 'learning_rate': 2.010968921389397e-06, 'epoch': 2.88}\n",
            "{'loss': 0.0519, 'grad_norm': 0.09822796285152435, 'learning_rate': 1.9347958561852528e-06, 'epoch': 2.88}\n",
            "{'loss': 0.0672, 'grad_norm': 0.31785285472869873, 'learning_rate': 1.8586227909811093e-06, 'epoch': 2.89}\n",
            "{'loss': 0.0018, 'grad_norm': 0.033551719039678574, 'learning_rate': 1.7824497257769653e-06, 'epoch': 2.89}\n",
            "{'loss': 0.0815, 'grad_norm': 0.036839816719293594, 'learning_rate': 1.7062766605728214e-06, 'epoch': 2.9}\n",
            "{'loss': 0.0072, 'grad_norm': 2.52805757522583, 'learning_rate': 1.6301035953686777e-06, 'epoch': 2.9}\n",
            "{'loss': 0.0216, 'grad_norm': 0.03394585847854614, 'learning_rate': 1.5539305301645339e-06, 'epoch': 2.91}\n",
            "{'loss': 0.1569, 'grad_norm': 0.09521958976984024, 'learning_rate': 1.47775746496039e-06, 'epoch': 2.91}\n",
            "{'loss': 0.1311, 'grad_norm': 18.81229019165039, 'learning_rate': 1.4015843997562462e-06, 'epoch': 2.92}\n",
            "{'loss': 0.2017, 'grad_norm': 43.42118835449219, 'learning_rate': 1.3254113345521023e-06, 'epoch': 2.92}\n",
            "{'loss': 0.0437, 'grad_norm': 2.962960720062256, 'learning_rate': 1.2492382693479586e-06, 'epoch': 2.93}\n",
            "{'loss': 0.0132, 'grad_norm': 0.09267949312925339, 'learning_rate': 1.1730652041438148e-06, 'epoch': 2.93}\n",
            "{'loss': 0.028, 'grad_norm': 0.035721827298402786, 'learning_rate': 1.096892138939671e-06, 'epoch': 2.93}\n",
            "{'loss': 0.0642, 'grad_norm': 7.454813480377197, 'learning_rate': 1.0207190737355273e-06, 'epoch': 2.94}\n",
            "{'loss': 0.0763, 'grad_norm': 0.02800271473824978, 'learning_rate': 9.445460085313834e-07, 'epoch': 2.94}\n",
            "{'loss': 0.0552, 'grad_norm': 0.026933537796139717, 'learning_rate': 8.683729433272396e-07, 'epoch': 2.95}\n",
            "{'loss': 0.1406, 'grad_norm': 20.578418731689453, 'learning_rate': 7.921998781230957e-07, 'epoch': 2.95}\n",
            "{'loss': 0.0364, 'grad_norm': 0.019803553819656372, 'learning_rate': 7.160268129189518e-07, 'epoch': 2.96}\n",
            "{'loss': 0.0603, 'grad_norm': 0.02583339810371399, 'learning_rate': 6.398537477148081e-07, 'epoch': 2.96}\n",
            "{'loss': 0.0394, 'grad_norm': 0.22548486292362213, 'learning_rate': 5.636806825106642e-07, 'epoch': 2.97}\n",
            "{'loss': 0.0498, 'grad_norm': 4.599307537078857, 'learning_rate': 4.875076173065205e-07, 'epoch': 2.97}\n",
            "{'loss': 0.0414, 'grad_norm': 0.17422319948673248, 'learning_rate': 4.113345521023766e-07, 'epoch': 2.98}\n",
            "{'loss': 0.0409, 'grad_norm': 0.024583904072642326, 'learning_rate': 3.351614868982328e-07, 'epoch': 2.98}\n",
            "{'loss': 0.011, 'grad_norm': 0.022153740748763084, 'learning_rate': 2.58988421694089e-07, 'epoch': 2.98}\n",
            "{'loss': 0.0295, 'grad_norm': 0.03112991712987423, 'learning_rate': 1.8281535648994517e-07, 'epoch': 2.99}\n",
            "{'loss': 0.0567, 'grad_norm': 0.37474963068962097, 'learning_rate': 1.0664229128580134e-07, 'epoch': 2.99}\n",
            "{'loss': 0.0013, 'grad_norm': 0.027385877445340157, 'learning_rate': 3.046922608165753e-08, 'epoch': 3.0}\n",
            "{'train_runtime': 18137.469, 'train_samples_per_second': 5.789, 'train_steps_per_second': 0.362, 'train_loss': 0.1482404835655829, 'epoch': 3.0}\n",
            "Total Training Time: 302.30 min\n"
          ]
        }
      ],
      "source": [
        "# Train model by calling trainer.train method\n",
        "start_time = time.time()\n",
        "trainer.train()\n",
        "print(f\"Total Training Time: {(time.time() - start_time)/60:.2f} min\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGEtKcuOMlW4"
      },
      "source": [
        "After training has completed, we can call `trainer.evaluate` to obtain the model performance on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jdmlq3rpMlW4",
        "outputId": "aaa26059-8714-4e9e-bd7a-708c9a490598",
        "colab": {
          "referenced_widgets": [
            "dc6c734d32c04f2cb2f7102dacc397af"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc6c734d32c04f2cb2f7102dacc397af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/625 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.29338061809539795, 'eval_accuracy': 0.9378, 'eval_runtime': 223.274, 'eval_samples_per_second': 44.788, 'eval_steps_per_second': 2.799, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "print(trainer.evaluate())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py46TlQzMlW4"
      },
      "source": [
        "The evaluation accuracy is around 94%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfgnV1lzMlW4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}